{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VO6FhoI5NXD",
        "outputId": "d00bec4e-d077-4591-dfda-8e16c4366b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss 1.363\n",
            "Epoch 2/10, Loss 0.462\n",
            "Epoch 3/10, Loss 0.309\n",
            "Epoch 4/10, Loss 0.253\n",
            "Epoch 5/10, Loss 0.225\n",
            "Epoch 6/10, Loss 0.205\n",
            "Epoch 7/10, Loss 0.184\n",
            "Epoch 8/10, Loss 0.162\n",
            "Epoch 9/10, Loss 0.173\n",
            "Epoch 10/10, Loss 0.163\n",
            "\n",
            "True: <SOS> This image has 1 stars <EOS>\n",
            "Pred: This image has 1 stars\n",
            "\n",
            "True: <SOS> This image has 9 stars <EOS>\n",
            "Pred: This image has 9 stars\n",
            "\n",
            "True: <SOS> This image has 6 stars <EOS>\n",
            "Pred: This image has 7 stars\n",
            "\n",
            "True: <SOS> This image has 1 stars <EOS>\n",
            "Pred: This image has 0 stars\n",
            "\n",
            "True: <SOS> This image has 6 stars <EOS>\n",
            "Pred: This image has 7 stars\n"
          ]
        }
      ],
      "source": [
        "# starcapnet.py — Multimodal Image Captioning (Image → Text)\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np, random\n",
        "\n",
        "# --- Config ---\n",
        "IMG_SIZE = 64\n",
        "VOCAB = [\"<PAD>\", \"<SOS>\", \"<EOS>\", \"This\", \"image\", \"has\", \"stars\", \"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
        "WORD2IDX = {w:i for i,w in enumerate(VOCAB)}\n",
        "IDX2WORD = {i:w for w,i in WORD2IDX.items()}\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "EMB_DIM, HIDDEN_DIM = 32, 64\n",
        "BATCH_SIZE, EPOCHS, LR = 32, 10, 1e-3\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- Synthetic star images ---\n",
        "def make_star_image(H, W, k, min_r=2, max_r=4, margin=5):\n",
        "    img = np.zeros((H, W), dtype=np.float32)\n",
        "    y = np.arange(H).reshape(-1,1); x = np.arange(W).reshape(1,-1)\n",
        "    for _ in range(k):\n",
        "        r = np.random.randint(min_r, max_r+1)\n",
        "        cy = np.random.randint(margin+r, H-margin-r)\n",
        "        cx = np.random.randint(margin+r, W-margin-r)\n",
        "        mask = (y-cy)**2+(x-cx)**2 <= r**2\n",
        "        img[mask] = 1.0\n",
        "    return img\n",
        "\n",
        "def generate_dataset(n=500):\n",
        "    X, captions = [], []\n",
        "    for _ in range(n):\n",
        "        count = np.random.randint(0,10)\n",
        "        img = make_star_image(IMG_SIZE, IMG_SIZE, count)\n",
        "        caption = [\"<SOS>\", \"This\", \"image\", \"has\", str(count), \"stars\", \"<EOS>\"]\n",
        "        X.append(img); captions.append(caption)\n",
        "    return np.array(X), captions\n",
        "\n",
        "def caption_to_ids(caption, max_len=7):\n",
        "    ids = [WORD2IDX[w] for w in caption]\n",
        "    if len(ids)<max_len: ids += [WORD2IDX[\"<PAD>\"]] * (max_len-len(ids))\n",
        "    return ids\n",
        "\n",
        "# --- Dataset ---\n",
        "class StarCaptionDataset(Dataset):\n",
        "    def __init__(self, n=500):\n",
        "        X, cap = generate_dataset(n)\n",
        "        self.X = torch.tensor(X).unsqueeze(1).float()\n",
        "        self.Y = torch.tensor([caption_to_ids(c) for c in cap])\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, idx): return self.X[idx], self.Y[idx]\n",
        "\n",
        "# --- Model ---\n",
        "class StarCapNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Image encoder (CNN)\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1,16,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        self.enc2feat = nn.Linear(32*(IMG_SIZE//4)*(IMG_SIZE//4), HIDDEN_DIM)\n",
        "\n",
        "        # Text decoder (Embedding + GRU)\n",
        "        self.embed = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
        "        self.gru = nn.GRU(EMB_DIM, HIDDEN_DIM, batch_first=True)\n",
        "        self.fc = nn.Linear(HIDDEN_DIM, VOCAB_SIZE)\n",
        "\n",
        "    def forward(self, images, captions):\n",
        "        # Encode image\n",
        "        feat = self.cnn(images)\n",
        "        h0 = self.enc2feat(feat).unsqueeze(0)  # initial hidden state\n",
        "\n",
        "        # Embed text & run GRU\n",
        "        emb = self.embed(captions[:,:-1])  # input all but last token\n",
        "        out,_ = self.gru(emb, h0)\n",
        "        logits = self.fc(out)  # predict next tokens\n",
        "        return logits\n",
        "\n",
        "    def generate(self, image, max_len=7):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            feat = self.cnn(image.unsqueeze(0))\n",
        "            h = self.enc2feat(feat).unsqueeze(0)\n",
        "            word = torch.tensor([[WORD2IDX[\"<SOS>\"]]], device=image.device)\n",
        "            caption = []\n",
        "            for _ in range(max_len):\n",
        "                emb = self.embed(word)\n",
        "                out,h = self.gru(emb,h)\n",
        "                logits = self.fc(out[:,-1])\n",
        "                word = logits.argmax(1).unsqueeze(0)\n",
        "                w = IDX2WORD[word.item()]\n",
        "                if w==\"<EOS>\": break\n",
        "                caption.append(w)\n",
        "            return \" \".join(caption)\n",
        "\n",
        "# --- Train ---\n",
        "def train():\n",
        "    ds = StarCaptionDataset(1000)\n",
        "    loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    model = StarCapNet().to(DEVICE)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=WORD2IDX[\"<PAD>\"])\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train(); total_loss=0\n",
        "        for xb,yb in loader:\n",
        "            xb,yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            logits = model(xb,yb)\n",
        "            loss = loss_fn(logits.reshape(-1,VOCAB_SIZE), yb[:,1:].reshape(-1))\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS}, Loss {total_loss/len(loader):.3f}\")\n",
        "\n",
        "    # Test on a few images\n",
        "    test_ds = StarCaptionDataset(5)\n",
        "    for i in range(5):\n",
        "        img, cap = test_ds[i]\n",
        "        pred = model.generate(img.to(DEVICE))\n",
        "        true = \" \".join([IDX2WORD[id.item()] for id in cap if id.item()!=0])\n",
        "        print(f\"\\nTrue: {true}\\nPred: {pred}\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    train()\n"
      ]
    }
  ]
}