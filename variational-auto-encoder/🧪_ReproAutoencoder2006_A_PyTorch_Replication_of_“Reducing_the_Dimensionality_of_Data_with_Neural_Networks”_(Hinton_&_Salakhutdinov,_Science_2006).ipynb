{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìñ Reducing the Dimensionality of Data with Neural Networks (Hinton & Salakhutdinov, 2006)\n",
        "\n",
        "# https://www.cs.toronto.edu/~hinton/absps/science.pdf\n",
        "\n",
        "## üîé Abstract\n",
        "This landmark paper introduced **deep autoencoders** as a nonlinear method for **dimensionality reduction**, significantly outperforming Principal Components Analysis (PCA).  \n",
        "The key innovation is a **layer-wise pretraining** strategy using **Restricted Boltzmann Machines (RBMs)** to initialize deep networks, followed by fine-tuning with backpropagation.  \n",
        "This overcame the optimization difficulties of training deep neural networks at the time and paved the way for modern deep learning.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Purpose\n",
        "- Develop a method to reduce **high-dimensional data** into compact, **low-dimensional codes**.  \n",
        "- Achieve reconstructions that preserve more **nonlinear structure** than PCA.  \n",
        "- Enable applications in **visualization, classification, retrieval, and storage**.  \n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Methodology\n",
        "\n",
        "### 1. Autoencoder Framework\n",
        "- Encoder compresses input $x$ into a low-dimensional **code**.  \n",
        "- Decoder reconstructs $x$ from the code.  \n",
        "- Trained by minimizing reconstruction error.\n",
        "\n",
        "### 2. Pretraining with Restricted Boltzmann Machines (RBMs)\n",
        "- Each layer is pretrained as an RBM to model correlations in the layer below.  \n",
        "- After stacking RBMs, they are ‚Äúunrolled‚Äù into a deep autoencoder.  \n",
        "- Fine-tuned with gradient descent for optimal reconstruction.  \n",
        "\n",
        "### 3. Experiments\n",
        "- **Synthetic Curves Dataset:** Learned 6D codes that nearly perfectly reconstructed images.  \n",
        "- **MNIST Handwritten Digits:** Autoencoder codes (30D, 2D) yielded superior reconstructions and visualizations compared to PCA.  \n",
        "- **Olivetti Faces Dataset:** Deep autoencoders outperformed PCA in compressing and reconstructing face images.  \n",
        "- **Text Documents (Reuters Corpus):** Learned codes improved **document retrieval** compared to Latent Semantic Analysis (LSA).  \n",
        "\n",
        "---\n",
        "\n",
        "## üìä Results\n",
        "- Deep autoencoders achieved **lower reconstruction errors** than PCA with the same dimensionality.  \n",
        "- 2D codes produced **clearer class separation** for visualization than PCA projections.  \n",
        "- For document retrieval, autoencoders provided more **semantically meaningful codes** than LSA.  \n",
        "- Pretraining greatly improved generalization and reduced error rates on classification tasks.  \n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Conclusions\n",
        "- Introduced the **first practical training method** for deep autoencoders via **layer-wise pretraining**.  \n",
        "- Demonstrated that deep neural networks can learn **nonlinear, compact representations** that outperform PCA.  \n",
        "- Marked a **turning point in deep learning**, inspiring later advances in unsupervised learning and representation learning.  \n",
        "\n",
        "**Impact:**  \n",
        "This paper is considered a **breakthrough in deep learning history**, laying the groundwork for modern **representation learning, generative models, and deep architectures**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "r1d0Ivn6xRYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìê Mathematical Formulation of the Deep Autoencoder (Hinton & Salakhutdinov, 2006)\n",
        "\n",
        "## 1. Encoder Mapping\n",
        "The input vector $x \\in \\mathbb{R}^D$ is mapped to a lower-dimensional code $z \\in \\mathbb{R}^d$ through multiple nonlinear layers:\n",
        "\n",
        "$$\n",
        "h^{(1)} = f(W^{(1)} x + b^{(1)})\n",
        "$$\n",
        "\n",
        "$$\n",
        "h^{(2)} = f(W^{(2)} h^{(1)} + b^{(2)})\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\;\\;\\vdots\n",
        "$$\n",
        "\n",
        "$$\n",
        "z = f(W^{(L)} h^{(L-1)} + b^{(L)})\n",
        "$$\n",
        "\n",
        "- $W^{(l)}$: weight matrix at layer $l$  \n",
        "- $b^{(l)}$: bias vector at layer $l$  \n",
        "- $f(\\cdot)$: nonlinear activation (e.g., sigmoid, ReLU)  \n",
        "- $z$: low-dimensional **code layer** (bottleneck representation)  \n",
        "\n",
        "---\n",
        "\n",
        "## 2. Decoder Mapping\n",
        "The decoder reconstructs the input from the code $z$ via symmetric layers:\n",
        "\n",
        "$$\n",
        "\\hat{h}^{(L-1)} = f(W^{(L+1)} z + b^{(L+1)})\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{h}^{(L-2)} = f(W^{(L+2)} \\hat{h}^{(L-1)} + b^{(L+2)})\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\;\\;\\vdots\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{x} = g(W^{(2L)} \\hat{h}^{(1)} + b^{(2L)})\n",
        "$$\n",
        "\n",
        "- $g(\\cdot)$: output activation (sigmoid for images in $[0,1]$)  \n",
        "- $\\hat{x}$: reconstruction of the input  \n",
        "\n",
        "---\n",
        "\n",
        "## 3. Objective Function\n",
        "The model minimizes the **reconstruction error** between input $x$ and output $\\hat{x}$.  \n",
        "\n",
        "### For real-valued data (MSE):\n",
        "$$\n",
        "\\mathcal{L}_{\\text{MSE}} = \\frac{1}{N} \\sum_{i=1}^N \\| x^{(i)} - \\hat{x}^{(i)} \\|^2\n",
        "$$\n",
        "\n",
        "### For binary data (cross-entropy):\n",
        "$$\n",
        "\\mathcal{L}_{\\text{CE}} = - \\frac{1}{N} \\sum_{i=1}^N \\left[ x^{(i)} \\log \\hat{x}^{(i)} + (1 - x^{(i)}) \\log (1 - \\hat{x}^{(i)}) \\right]\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Pretraining (Restricted Boltzmann Machine ‚Äì RBM)\n",
        "Each layer is pretrained as an RBM to initialize weights.  \n",
        "\n",
        "The **energy function** of an RBM is:\n",
        "\n",
        "$$\n",
        "E(v,h) = - \\sum_i b_i v_i - \\sum_j c_j h_j - \\sum_{i,j} v_i h_j W_{ij}\n",
        "$$\n",
        "\n",
        "- $v_i$: visible unit  \n",
        "- $h_j$: hidden unit  \n",
        "- $W_{ij}$: weight  \n",
        "- $b_i, c_j$: biases  \n",
        "\n",
        "The probability of a visible vector is:\n",
        "\n",
        "$$\n",
        "P(v) = \\frac{1}{Z} \\sum_h e^{-E(v,h)}\n",
        "$$\n",
        "\n",
        "where $Z$ is the partition function.\n",
        "\n",
        "Weight updates use Contrastive Divergence (CD):\n",
        "\n",
        "$$\n",
        "\\Delta W_{ij} \\propto \\langle v_i h_j \\rangle_{\\text{data}} - \\langle v_i h_j \\rangle_{\\text{recon}}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Training Strategy\n",
        "1. **Pretrain** each layer as an RBM (greedy layer-wise).  \n",
        "2. **Unroll** the pretrained RBMs into encoder-decoder form.  \n",
        "3. **Fine-tune** the whole autoencoder using backpropagation with the chosen reconstruction loss.  \n",
        "\n",
        "---\n",
        "\n",
        "## 6. Learned Low-Dimensional Codes\n",
        "The bottleneck representation $z$ is a **nonlinear low-dimensional embedding**:\n",
        "\n",
        "$$\n",
        "z = f_{\\theta}(x), \\quad \\text{with} \\quad \\dim(z) \\ll \\dim(x)\n",
        "$$\n",
        "\n",
        "This $z$ can be used for:\n",
        "- Visualization (e.g., $z \\in \\mathbb{R}^2$).  \n",
        "- Classification.  \n",
        "- Retrieval and clustering.  \n",
        "- Compression.  \n"
      ],
      "metadata": {
        "id": "HG_E-DIMyi3h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2bA_0osxQsu",
        "outputId": "74ef62af-51aa-4f37-afce-f2728426a40c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# üìñ ReproAutoencoder2006: PyTorch Replication of\n",
        "# \"Reducing the Dimensionality of Data with Neural Networks\" (Hinton & Salakhutdinov, 2006)\n",
        "\n",
        "# 1. üì¶ Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ‚öôÔ∏è Config\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "lr = 1e-3\n",
        "code_dim = 30   # Bottleneck (like in the paper for MNIST)\n"
      ],
      "metadata": {
        "id": "7nqaf08uxf2q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. üìÇ Dataset (MNIST)\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2cucrRCxiTz",
        "outputId": "c3280b1c-e213-47f5-873c-ba8a475867fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:00<00:00, 18.7MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 500kB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:00<00:00, 4.68MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 9.95MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. üß† Deep Autoencoder\n",
        "class DeepAutoencoder(nn.Module):\n",
        "    def __init__(self, code_dim=30):\n",
        "        super().__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28*28, 1000),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1000, 500),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(500, 250),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(250, code_dim)  # Bottleneck\n",
        "        )\n",
        "        # Decoder (symmetric)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(code_dim, 250),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(250, 500),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(500, 1000),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1000, 28*28),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        out = self.decoder(z)\n",
        "        return out, z\n",
        "\n",
        "model = DeepAutoencoder(code_dim=code_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.MSELoss()\n"
      ],
      "metadata": {
        "id": "dBg5_cNIxlQo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. üöÄ Training Loop\n",
        "train_losses = []\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x, _ in tqdm(train_loader):\n",
        "        x = x.view(x.size(0), -1).to(device)\n",
        "        optimizer.zero_grad()\n",
        "        x_hat, _ = model(x)\n",
        "        loss = criterion(x_hat, x)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    train_losses.append(avg_loss)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXfgjBzmxoWo",
        "outputId": "cceb83c1-81ec-4be8-9a6c-1e072abbdbae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 58.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.0477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 65.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20, Loss: 0.0245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 65.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20, Loss: 0.0195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 65.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20, Loss: 0.0161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 64.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20, Loss: 0.0135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 64.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20, Loss: 0.0119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 65.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20, Loss: 0.0108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 65.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20, Loss: 0.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 64.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20, Loss: 0.0093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 65.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20, Loss: 0.0087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 64.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20, Loss: 0.0082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 65.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20, Loss: 0.0078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 65.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20, Loss: 0.0075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 64.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20, Loss: 0.0071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 65.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20, Loss: 0.0069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 65.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20, Loss: 0.0067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 65.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20, Loss: 0.0065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 65.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20, Loss: 0.0063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 64.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20, Loss: 0.0061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:07<00:00, 64.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20, Loss: 0.0060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. üîç Evaluation ‚Äì Reconstructions\n",
        "model.eval()\n",
        "examples = iter(test_loader)\n",
        "x, _ = next(examples)\n",
        "x = x.view(x.size(0), -1).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    x_hat, codes = model(x)\n",
        "\n",
        "# Show original vs reconstruction\n",
        "n = 8\n",
        "fig, axes = plt.subplots(2, n, figsize=(12,4))\n",
        "for i in range(n):\n",
        "    axes[0,i].imshow(x[i].cpu().view(28,28), cmap=\"gray\")\n",
        "    axes[0,i].axis(\"off\")\n",
        "    axes[1,i].imshow(x_hat[i].cpu().view(28,28), cmap=\"gray\")\n",
        "    axes[1,i].axis(\"off\")\n",
        "axes[0,0].set_title(\"Originals\")\n",
        "axes[1,0].set_title(\"Reconstructions\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "lNG2jz7txrQe",
        "outputId": "167e661b-4a6f-4c92-9787-7b50cbea948f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 16 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8cAAAE1CAYAAADKypJhAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARD9JREFUeJzt3Xd8VNW2wPEVCCSUgAFCDZIQkBo6qEgVHkgTkCKISFNBFLCADQHFwhUs+EBBrwoqiBQFUQRBL0VQvIr0KmAoSoDQCSAl5/3hc7v3TmZIwswkmfP7fj5+PmuzJjM7OXNmZjt7nRXiOI4jAAAAAAC4WK6sngAAAAAAAFmNxTEAAAAAwPVYHAMAAAAAXI/FMQAAAADA9VgcAwAAAABcj8UxAAAAAMD1WBwDAAAAAFyPxTEAAAAAwPVYHAMAAAAAXM+Vi+Nnn31WQkJCMvWz06dPl5CQEElISPDtpDQJCQkSEhIi06dP99tjAAAAAAD+keMWx1u3bpW7775bypQpI2FhYVK6dGnp1auXbN26NaunBgAAAADIoUIcx3GyehLp9dlnn0nPnj2lSJEiMmDAAImNjZWEhAR577335NixY/LJJ59I586dr3o/ly9flsuXL0t4eHiG53DlyhW5dOmShIWFZfrb56tJSEiQ2NhYmTZtmvTt29cvjwEAAAAA+EdoVk8gvfbs2SO9e/eW8uXLy6pVqyQqKkrlhg0bJo0bN5bevXvLpk2bpHz58mneR3JyshQoUEBCQ0MlNDRzv3ru3Lkld+7cmfpZAAAAAED2lGO2VU+YMEHOnTsn77zzjrEwFhEpVqyYvP3225KcnCzjx48XkX/qirdt2yZ33XWXREZGSqNGjYyc7vz58zJ06FApVqyYREREyO233y6///67hISEyLPPPqtul1bNcUxMjLRv315Wr14tDRo0kPDwcClfvrx8+OGHxmMcP35chg8fLvHx8VKwYEEpVKiQtGnTRjZu3HjV3z8xMVH69esn0dHREhYWJqVKlZKOHTv6tfYZAAAAANwix3xz/MUXX0hMTIw0btw4zXyTJk0kJiZGFi1aZPx7t27dpGLFivLSSy+Jtx3kffv2lTlz5kjv3r3lpptukpUrV0q7du3SPb/du3dL165dZcCAAdKnTx95//33pW/fvlK3bl2pVq2aiIjs3btXFixYIN26dZPY2Fg5fPiwvP3229K0aVPZtm2blC5d2uP9d+nSRbZu3SpDhgyRmJgYOXLkiCxbtkz2798vMTEx6Z4nAAAAACC1HLE4PnXqlPzxxx/SsWNHr7erUaOGLFy4UM6cOaP+rWbNmvLxxx97/blffvlF5syZIw8//LC8/vrrIiIyePBg6devX7q+1RUR2blzp6xatUot3rt37y5ly5aVadOmySuvvCIiIvHx8bJr1y7JleufL+x79+4tlStXlvfee09GjRqV5n2fPHlSvv/+e5kwYYIMHz5c/ftTTz2VrrkBAAAAALzLEduq/17sRkREeL3d3/nTp0+rfxs0aNBV73/JkiUi8teCWDdkyJB0z7Fq1arGt9pRUVFSqVIl2bt3r/q3sLAwtTC+cuWKHDt2TAoWLCiVKlWSX375xeN958uXT/LmzSsrVqyQEydOpHtOAAAAAID0yRGL478Xvfo3wmlJaxEdGxt71fvft2+f5MqVK9VtK1SokO45Xn/99an+LTIy0ljMpqSkyOuvvy4VK1aUsLAwKVasmERFRcmmTZvk1KlTHu87LCxMXn75ZVm8eLGUKFFCmjRpIuPHj5fExMR0zw8AAAAA4FmOWBwXLlxYSpUqJZs2bfJ6u02bNkmZMmWkUKFC6t/y5cvn7+mJiHi8grVe5/zSSy/Jo48+Kk2aNJEZM2bI119/LcuWLZNq1apJSkqK1/t/+OGHZdeuXTJu3DgJDw+XUaNGSZUqVWT9+vU+/T0AAAAAwI1yxOJYRKR9+/by22+/yerVq9PMf/fdd5KQkCDt27fP8H2XK1dOUlJS5LfffjP+fffu3Zmaqyfz5s2T5s2by3vvvSc9evSQVq1aScuWLeXkyZPp+vm4uDh57LHHZOnSpbJlyxa5ePGivPrqqz6dIwAAAAC4UY5ZHI8YMULy5csnAwcOlGPHjhm548ePy6BBgyR//vwyYsSIDN9369atRUTkrbfeMv590qRJmZ9wGnLnzp3qitlz586V33//3evPnTt3Ti5cuGD8W1xcnERERMiff/7p0zkCAAAAgBvliKtVi4hUrFhRPvjgA+nVq5fEx8fLgAEDJDY2VhISEuS9996TpKQkmTVrlsTFxWX4vuvWrStdunSRiRMnyrFjx1Qrp127domIpOqJnFnt27eXsWPHSr9+/aRhw4ayefNmmTlzppQvX97rz+3atUtatGgh3bt3l6pVq0poaKjMnz9fDh8+LD169PDJ3AAAAADAzXLM4ljkr57FlStXlnHjxqkFcdGiRaV58+by9NNPS/Xq1TN93x9++KGULFlSZs2aJfPnz5eWLVvK7NmzpVKlShIeHu6T+T/99NOSnJwsH3/8scyePVvq1KkjixYtkieffNLrz5UtW1Z69uwp3377rXz00UcSGhoqlStXljlz5kiXLl18MjcAAAAAcLMQx97nC2XDhg1Su3ZtmTFjhvTq1SurpwMAAAAA8JMcU3Psb+fPn0/1bxMnTpRcuXJJkyZNsmBGAAAAAIBAyVHbqv1p/Pjxsm7dOmnevLmEhobK4sWLZfHixXL//fdL2bJls3p6AAAAAAA/Ylv1/1u2bJk899xzsm3bNjl79qxcf/310rt3bxk5cqSEhvL/EAAAAAAgmLE4BgAAAAC4HjXHAAAAAADXY3EMAAAAAHA9FscAAAAAANcL6JWmQkJCAvlw8MLXpeYc2+yDYxu8fHlsOa7ZB+ds8OLYBi9ej4MT52zwSu+x5ZtjAAAAAIDrsTgGAAAAALgei2MAAAAAgOuxOAYAAAAAuB6LYwAAAACA67E4BgAAAAC4HotjAAAAAIDrsTgGAAAAALgei2MAAAAAgOuxOAYAAAAAuF5oVk8A8LXhw4cb43z58qm4Ro0aRq5r164e72fKlCnG+IcfflDxRx99dC1TBAAAAJDN8M0xAAAAAMD1WBwDAAAAAFwvxHEcJ2APFhISqIfCVfj6sGf1sZ09e7aKvW2VvhZ79uxRccuWLY3c/v37/fKYmRFsxzYQbrjhBhXv2LHDyA0bNkzFkyZNCtic0uLLY5tTjmuBAgWM8YQJE1Q8cOBAI7du3Tpj3K1bNxXv27fPD7PzDc7Z4MWxDV5ufD12A87Z4JXeY8s3xwAAAAAA12NxDAAAAABwPRbHAAAAAADXo5UTciS9xlgk/XXGdj3p119/reLy5csbuQ4dOhjjuLg4Fffq1cvIjRs3Ll2Pj+ypdu3aKk5JSTFyBw8eDPR0oClVqpQxvu+++1RsH6u6desa4/bt26v4zTff9MPscDV16tQxxp999pmKY2Ji/P74rVq1Msbbt29X8YEDB/z++Mg4/b134cKFRu6hhx5S8dSpU43clStX/DuxIFa8eHEVz5kzx8h9//33Kn7nnXeMXEJCgl/nZStcuLAxbtKkiYqXLFli5C5duhSQOSH48M0xAAAAAMD1WBwDAAAAAFyPbdXIMerVq6fizp07e7zd1q1bjfHtt9+u4qSkJCN39uxZFefNm9fIrV271hjXrFlTxUWLFk3HjJFT1KpVS8XJyclGbv78+QGeDaKiolT8wQcfZOFMcK1at25tjMPCwgL6+HZ5TP/+/VXco0ePgM4FabPfT9966y2Pt508ebKK33//fSN3/vx5304siEVGRhpj/XOTvXX58OHDKg70NmoRcz52uz79vcIuq9m9e7d/JxYEChUqpGK7PLB69eoqttuXBvuWdb45BgAAAAC4HotjAAAAAIDrsTgGAAAAALhejq85tlv46G0+/vjjDyN34cIFFc+cOdPIJSYmqpg6hexJb+kSEhJi5PR6GbvG7dChQ+m6/8cee8wYV61a1eNtFy1alK77RPak19KImO1BPvroo0BPx/WGDh1qjDt16qTiBg0aZPp+9TYfuXKZ/y9448aNKl61alWmHwOphYb+89Gibdu2WTiT1DWKjz76qIoLFChg5OzrDSAw9PNURCQ6OtrjbWfNmqVi/TMdrq5YsWIqttthFilSRMV2zfeQIUP8O7GreOaZZ1QcGxtr5AYOHKhiPrtfnd2G9MUXX1Rx2bJlPf6cXpssInLs2DHfTiyb4ZtjAAAAAIDrsTgGAAAAALheiOM4TsAezNoK6wt79+41xjExMZm6nzNnzqjYbgUUCAcPHlTx+PHjjdzPP//s88fz9WH3x7H1ply5csZYP37Hjx/P1H3q2yxFUm+91dmXtV++fHmmHtMfcvqxDQS7HGPOnDkqbt68uZFbuXJlQOaUHr48ttnpuF65csUYp6SkZOp+7K3T3u5n3759Kr7zzjuNnL0V19+C7Zz9n//5HxUvXrzYyOnvb08//bTf5/LII48Y4wkTJqhYL9URETl69KjPHz/Yjq0v2O281qxZY4ztljw6fZu+/dwKtJz2etyqVSsVe/vblSxZ0hj747zwplq1asZ48+bNKrZbK/bt21fF+ufAaxFs56xeprB+/Xojp7dR8/Z729vw9VI0kcx/7g609B5bvjkGAAAAALgei2MAAAAAgOuxOAYAAAAAuF6Ob+Wkt24SEalRo4aKt2/fbuSqVKmi4jp16hi5Zs2aqfimm24ycgcOHFCxt0ud2y5fvmyM9boNu9ZJt3//fmPsj5rjnE6vF7wWI0aMUPENN9zg9bY//vhjmjFynscff9wY688nzrfA+Oqrr1Rs1wpnlt1e4uzZsyq2r1OgtwT573//a+Ry587tk/m4hX19Br3dzp49e4zcSy+9FJA5/a1jx44BfTxcXXx8vDH2VmNsf47K6jrjnKR48eLGuEuXLh5vO2DAABUHusZYxKwz/uabbzzezq459lWdcTAbPny4ivWWXRlhX5fjtttuM8Z6S6hJkyYZuYsXL2bqMbMS3xwDAAAAAFyPxTEAAAAAwPVy/Lbqb7/91utYt2TJEo+5yMhIFdeqVcvI6W096tevn+65XbhwwRjv2rVLxfaWb32rg70NDb7Tvn17Yzx27FgV582b18gdOXLEGD/11FMqPnfunB9mB3+xW7zVq1fPGOvnZnJyciCm5DpNmzY1xpUqVVKx3XIpva2cpk6daoyXLl1qjE+dOqXiW2+91ciNHDnS4/0+8MADKp4yZUq65uJmzzzzjDEuUKCAiu3td/pWd3/R30/t511m24TBd7xt77XZ5zTS79VXXzXGd999t4rtdnVz584NyJw8ady4sYpLlChh5KZPn67iGTNmBGpKOZZdQtSvXz+Pt920aZOKDx8+bOTslqW6woULG2N96/bMmTONXGJioufJZlN8cwwAAAAAcD0WxwAAAAAA12NxDAAAAABwvRxfc+wrJ06cUPHy5cs93s5bTfPV6HU2eo2ziMjmzZtVPHv27Ew/Bryza03tOmOdfRxWrlzplznB/+y6Q1tWtK5wA73W+5NPPjFyxYoVS9d92G3bPv30UxU/99xzRs7btQDs+7n//vtVHBUVZeTGjx+v4vDwcCM3efJkFV+6dMnj4wW7rl27qrht27ZGbvfu3SrOitZoej25XWO8YsUKFZ88eTJAM4KuSZMmXvN66xdv1waAd47jGGP9XPjjjz+MXCDa7eTLl0/FTz/9tJEbPHiwiu159+/f378TCzL2dZMiIiJU/N133xk5/bOR/V7Xs2dPFdvHKy4uzhiXLFlSxZ9//rmRa9OmjYqPHz/uberZBt8cAwAAAABcj8UxAAAAAMD12FbtR8WLFzfGb731lopz5TL/v4TeUiinbDvIKRYsWKDiVq1aebzdhx9+aIzt9iTIueLj473m9W208J3Q0H/eYtK7jVrELGHo0aOHkUtKSsrUXOxt1ePGjVPxa6+9ZuTy58+vYvu5sXDhQhW7ue1et27dVKz/vUTM97pAsFu19erVS8VXrlwxci+88IKK3bwtPtAaNmyYZpwWvZ3ehg0b/DUlV2vXrp0x1ltm2eUGmW1nZ5czNWvWTMU33XSTx5+bN29eph4PfwkLCzPG+jb1119/3ePP2e1np02bpmL99V5EpHz58h7vxy5vCsSWfV/jm2MAAAAAgOuxOAYAAAAAuB6LYwAAAACA61Fz7EcPPvigMdbbheito0REdu7cGZA5uUGpUqWMsV7fZNdi6PWLei2aiMjZs2f9MDsEil7T1K9fPyO3fv16Y7xs2bKAzAlps9v96K07MltjfDV67bBeoyoiUr9+fb88Zk5WuHBhY+ytZjCzNYqZpbflEjHr27dv327kvLVqhP9k5JwK9PMnWL3xxhvGuHnz5iouXbq0kdPba4WEhBi522+/PVOPb9+P3aJJt3fvXhXbbYOQMXoLJptda65fk8cbuw2qN2vXrjXGOfGzNN8cAwAAAABcj8UxAAAAAMD12FbtY7fccouKn3zySY+369SpkzHesmWLv6bkOp9++qkxLlq0qMfbzpgxQ8VubssSjFq2bKniIkWKGLklS5YYY7uFAXzPbl+nu/HGGwM4k7/oW/7suXmb67PPPqvi3r17+3xe2ZVdklKmTBkVz5o1K9DTMcTFxXnM8d6aPXjblumr1kEwrVu3zhjXqFFDxbVq1TJyt912m4pHjBhh5I4ePariDz74IN2P/9FHHxnjjRs3erzt999/r2I+i10b+/VY3xZvlzdUrlxZxXbLy86dO6s4MjLSyNnnrJ6/7777jJz+PNi2bZu3qWcbfHMMAAAAAHA9FscAAAAAANdjcQwAAAAAcD1qjn2sbdu2Ks6TJ4+R+/bbb1X8ww8/BGxObqDXVNSpU8fj7VasWGGMx4wZ468pIYvVrFlTxXYLiXnz5gV6Oq40aNAgFaekpGThTFLr0KGDimvXrm3k9Lna89Zrjt3kzJkzxnjDhg0q1msZRcwa/+PHj/tlPsWLF1dx165dPd5u9erVfnl8eNeoUSNjfNddd3m87alTp4zxwYMH/TInt9NbiNotzfTxE0884ZPHK1++vDHWr/Ogv36IiAwfPtwnjwmRb775xhjr55ddV6zXAHtrtWXfp92q9ssvv1RxxYoVjdzQoUNVrH8myM745hgAAAAA4HosjgEAAAAArsfiGAAAAADgetQcX6N8+fIZY71X3MWLF42cXt966dIl/04syNm9i59++mkV27XeOrvO5ezZsz6dF7JOyZIljXHjxo1VvHPnTiM3f/78gMzJ7fS63qwQFRWl4qpVqxo5/TXDG73Hp4h7X7vPnz9vjPVepF26dDFyixYtUvFrr72WqcerXr26MbbrF2NiYlTsrVYuu9W6u4X9Hu2td/iyZcv8PR1kgdGjRxtj/Ty165rt11lknn2dh+7du6vYvt5K4cKFPd7PpEmTVGwfrwsXLhjjzz77TMVPPvmkkWvdurWK7Z702bWnNd8cAwAAAABcj8UxAAAAAMD12FZ9jUaMGGGM9ZYgS5YsMXLff/99QObkBo899pgxrl+/vsfbLliwQMW0bgpeffv2NcZ6q5fFixcHeDbIDkaOHKliu/WENwkJCSru06ePkdu/f/81zysY6K+leosWEZF27dqpeNasWZm6/6SkJGNsb50uVqxYuu5n+vTpmXp8XBtv7bVOnjxpjN9++20/zwaB0K1bN2N8zz33GGO9HdyxY8cCMieYbZjs81JvsWafl/q2eHsbte35559XcZUqVYyc3mrV3mpvv79mF3xzDAAAAABwPRbHAAAAAADXY3EMAAAAAHA9ao4zSK+lEhEZNWqUMT59+rSKx44dG5A5udGjjz6a7ts+9NBDKqZ1U/AqV66cx9yJEycCOBNkla+++soYV6pUKVP3s23bNhWvXr36muYUrHbs2KFivVWIiEitWrVUXKFChUzdv91yxPbBBx+ouFevXh5vZ7eggv9ER0erWK9ltB08eNAY//zzz36bEwKnTZs2XvNffvmlin/55Rd/Twdp0OuP0xpnlv46O3v2bCOn1xw3b97cyBUpUkTFdguqrMQ3xwAAAAAA12NxDAAAAABwPbZVp0PRokVV/L//+79GLnfu3MZY39a3du1a/04M6aJv27h06VKm7+fUqVMe7ydPnjwqLly4sMf7uO6664xxereHX7lyxRg/8cQTKj537ly67iPYtW/f3mPuiy++COBM8De9xU+uXJ7/X6y37XjvvPOOMS5durTH29qPkZKScrUppqlDhw6Z+jn8ZcOGDWnGvrR379503a569erGeMuWLf6YDkSkYcOGKvZ2vuvtFRE87Nfx5ORkY/zqq68GcjrIInPmzDHG+rbqO++808jpZY/ZqRSVb44BAAAAAK7H4hgAAAAA4HosjgEAAAAArkfNcRrsOuIlS5aoODY21sjt2bPHGNutnZD1Nm3a5JP7mTt3rooPHTpk5EqUKKFiu6bCHxITE1X84osv+v3xsqtGjRqpuGTJklk4E6RlypQpKh4/frzH2+ktPkS81wpnpI44vbedOnVquu8T2YNez67HNmqMA0e/PostKSlJxW+88UYgpoMAGDRokIr1z0EiIkeOHDHGtG9yB/t9V3/v79ixo5EbM2aMij/55BMjt2vXLj/MLn345hgAAAAA4HosjgEAAAAArse26jTExcUZ47p163q8rd2Kx95mDf/QW2aJpN6q4Q/dunXL1M9dvnxZxd62eS5cuNAY//zzzx5v+91332VqLsGmc+fOKrbLIdavX6/iVatWBWxO+Mdnn32m4hEjRhi5qKgovz/+0aNHVbx9+3Yjd//996vYLpNA9uc4Tpoxsk7r1q095vbv369ivS0icjZ9W7V9Hi5atMjjz0VERBjjyMhIFevPFeR8eju/0aNHG7kJEyao+KWXXjJyvXv3VvH58+f9MzkP+OYYAAAAAOB6LI4BAAAAAK7H4hgAAAAA4HrUHP+/cuXKqXjp0qUeb2fXzdktSBAYd9xxhzF+/PHHVZwnT55030+1atVUnJEWTO+//74xTkhI8HjbTz/9VMU7duxI92Mgtfz58xvjtm3berztvHnzVHzlyhW/zQme7du3T8U9evQwcp06dVLxsGHD/PL4epuzN9980y+PgawRHh7uMRfo+jS3st9r7eu16C5cuKDiS5cu+W1OyD7s991evXqp+JFHHjFyW7duVXGfPn38OzFkmQ8//NAYDxw4UMX25/qxY8eq2FctWdOLb44BAAAAAK7H4hgAAAAA4HohTgB7IISEhATqoTJM33731FNPebxdgwYNjLG3djvZma8Pe3Y+tm4TzMfW3sa3cuVKFR85csTI3XXXXSo+d+6cfycWIL48ttnpuN52223GWG+z1KFDByOntzx75513jJz9O23btk3F2bk9SDCfs/6SmJio4tBQs0Ls+eefV/Ebb7wRsDmlJZiPrd0+791331Vx3759jZy+nTJYts0G6+txRuhteuLj442c/Tvpf6/33nvPyOnn7IEDB3w4w4wL5nM2u7n++utVbJcnzpo1S8X6lvxrkd5jyzfHAAAAAADXY3EMAAAAAHA9FscAAAAAANdzbc1xo0aNjPFXX32l4oIFC3r8OWqO05adjq3bcWyDFzVuwYlzNuO++OILFb/22mtGbvny5YGejkduOralS5dW8QsvvGDk1q1bp+JgaavG67H5WVpvvSMismrVKmM8ZcoUFZ84ccLIXbx40Q+zyxw3nbPZid1G9+abb1bxjTfeaOT064lkBDXHAAAAAACkE4tjAAAAAIDrhV79JsGpcePGxtjbVuo9e/ao+OzZs36bEwAAuDq7xRey3h9//KHi/v37Z+FMECirV69W8a233pqFM0FO17VrV2O8ceNGFVeoUMHIZXZbdXrxzTEAAAAAwPVYHAMAAAAAXI/FMQAAAADA9Vxbc+yNvs9dRKRFixYqPn78eKCnAwAAAABB6fTp08Y4NjY2i2bCN8cAAAAAALA4BgAAAAAgxHEcJ2APFhISqIfCVfj6sHNssw+ObfDy5bHluGYfnLPBi2MbvHg9Dk6cs8ErvceWb44BAAAAAK7H4hgAAAAA4HosjgEAAAAArhfQmmMAAAAAALIjvjkGAAAAALgei2MAAAAAgOuxOAYAAAAAuB6LYwAAAACA67E4BgAAAAC4HotjAAAAAIDrsTgGAAAAALgei2MAAAAAgOuxOAYAAAAAuB6LYwAAAACA67E4BgAAAAC4HotjAAAAAIDrsTgGAAAAALgei2MAAAAAgOuxOAYAAAAAuB6LYwAAAACA67E4BgAAAAC4HotjAAAAAIDrsTgGAAAAALgei2MAAAAAgOuxOAYAAAAAuB6LYwAAAACA67E4BgAAAAC4HotjAAAAAIDrsTgGAAAAALgei2MAAAAAgOuxOAYAAAAAuB6LYwAAAACA67E4BgAAAAC4HotjAAAAAIDrsTgGAAAAALgei2MAAAAAgOuxOAYAAAAAuB6LYwAAAACA67E4BgAAAAC4HotjAAAAAIDrsTgGAAAAALgei2MAAAAAgOuxOAYAAAAAuB6LYwAAAACA67E4BgAAAAC4HotjAAAAAIDrsTgGAAAAALgei2MAAAAAgOuxOAYAAAAAuB6LYwAAAACA67E4zqFWrFghISEhsmLFiqyeCgAAAADkeBleHE+fPl1CQkLUf6GhoVKmTBnp27ev/P777/6YY5Z56623ZPr06a6fAwAAAAAEuxDHcZyM/MD06dOlX79+MnbsWImNjZULFy7I2rVrZfr06RITEyNbtmyR8PBwf803oKpXry7FihXL0m9nPc0hJSVFLl68KHnz5pVcudgAAAAAAADXIjSzP9imTRupV6+eiIjce++9UqxYMXn55Zdl4cKF0r17d59NMKdITk6WAgUKBOzxcuXKFTT/EwIAAAAAsprPvnJs3LixiIjs2bNH/duOHTuka9euUqRIEQkPD5d69erJwoULU/3syZMn5ZFHHpGYmBgJCwuT6OhoueeeeyQpKUnd5siRIzJgwAApUaKEhIeHS82aNeWDDz4w7ichIUFCQkLklVdekXfeeUfi4uIkLCxM6tevLz/99JNx28TEROnXr59ER0dLWFiYlCpVSjp27CgJCQkiIhITEyNbt26VlStXqi3kzZo1E5F/tpavXLlSBg8eLMWLF5fo6GgREenbt6/ExMSk+h2fffZZCQkJSfXvM2bMkAYNGkj+/PklMjJSmjRpIkuXLr3qHDzVHM+dO1fq1q0r+fLlk2LFisndd9+dart73759pWDBgvL7779Lp06dpGDBghIVFSXDhw+XK1euGLf95JNPpG7duhIRESGFChWS+Ph4eeONN1L9HgAAAACQk2X6m2Pb34vKyMhIERHZunWr3HLLLVKmTBl58sknpUCBAjJnzhzp1KmTfPrpp9K5c2cRETl79qw0btxYtm/fLv3795c6depIUlKSLFy4UA4ePCjFihWT8+fPS7NmzWT37t3y0EMPSWxsrMydO1f69u0rJ0+elGHDhhlz+fjjj+XMmTMycOBACQkJkfHjx8sdd9whe/fulTx58oiISJcuXWTr1q0yZMgQiYmJkSNHjsiyZctk//79EhMTIxMnTpQhQ4ZIwYIFZeTIkSIiUqJECeNxBg8eLFFRUTJ69GhJTk7O8N/sueeek2effVYaNmwoY8eOlbx588qPP/4o//nPf6RVq1bpmoPu7y3v9evXl3Hjxsnhw4fljTfekDVr1sj69evluuuuU7e9cuWKtG7dWm688UZ55ZVX5JtvvpFXX31V4uLi5IEHHhARkWXLlknPnj2lRYsW8vLLL4uIyPbt22XNmjWp/uYAAAAAkKM5GTRt2jRHRJxvvvnGOXr0qHPgwAFn3rx5TlRUlBMWFuYcOHDAcRzHadGihRMfH+9cuHBB/WxKSorTsGFDp2LFiurfRo8e7YiI89lnn6V6rJSUFMdxHGfixImOiDgzZsxQuYsXLzo333yzU7BgQef06dOO4zjOb7/95oiIU7RoUef48ePqtp9//rkjIs4XX3zhOI7jnDhxwhERZ8KECV5/12rVqjlNmzb1+Ddo1KiRc/nyZSPXp08fp1y5cql+ZsyYMY7+5/7111+dXLlyOZ07d3auXLmS5u/tbQ7Lly93RMRZvny5+nsUL17cqV69unP+/Hl1uy+//NIREWf06NHGHEXEGTt2rHGftWvXdurWravGw4YNcwoVKpTqdwQAAACAYJPpbdUtW7aUqKgoKVu2rHTt2lUKFCggCxculOjoaDl+/Lj85z//ke7du8uZM2ckKSlJkpKS5NixY9K6dWv59ddf1VbfTz/9VGrWrKm+Sdb9vQ35q6++kpIlS0rPnj1VLk+ePDJ06FA5e/asrFy50vi5O++8U32DLfLPlu+9e/eKiEi+fPkkb968smLFCjlx4kRm/wRy3333Se7cuTP1swsWLJCUlBQZPXp0qgtqpbX9+mp+/vlnOXLkiAwePNioRW7Xrp1UrlxZFi1alOpnBg0aZIwbN26s/kYiItddd50kJyfLsmXLMjwfAAAAAMhJMr04fvPNN2XZsmUyb948adu2rSQlJUlYWJiIiOzevVscx5FRo0ZJVFSU8d+YMWNE5K8aYpG/apSrV6/u9bH27dsnFStWTLWIrFKlisrrrr/+emP890L574VwWFiYvPzyy7J48WIpUaKENGnSRMaPHy+JiYkZ+hvExsZm6Pa6PXv2SK5cuaRq1aqZvg/d33+DSpUqpcpVrlw51d8oPDxcoqKijH+LjIw0/mfB4MGD5YYbbpA2bdpIdHS09O/fX5YsWeKT+QIAAABAdpLpmuMGDRqoq1V36tRJGjVqJHfddZfs3LlTUlJSRERk+PDh0rp16zR/vkKFCpl96Kvy9G2uo3Wtevjhh6VDhw6yYMEC+frrr2XUqFEybtw4+c9//iO1a9dO1+Pky5cv1b95+tbXvtBVVkvPN97FixeXDRs2yNdffy2LFy+WxYsXy7Rp0+See+5JdTE0AAAAAMjJfHK16ty5c8u4cePkjz/+kMmTJ0v58uVF5K+tzy1btkzzv4iICBERiYuLky1btni9/3Llysmvv/6qFt1/27Fjh8pnRlxcnDz22GOydOlS2bJli1y8eFFeffVVlc/M9ubIyEg5efJkqn+3v7mNi4uTlJQU2bZtm9f7S+8c/v4b7Ny5M1Vu586dmf4b5c2bVzp06CBvvfWW7NmzRwYOHCgffvih7N69O1P3BwAAAADZkc9aOTVr1kwaNGggEydOlEKFCkmzZs3k7bfflkOHDqW67dGjR1XcpUsX2bhxo8yfPz/V7f7+prdt27aSmJgos2fPVrnLly/LpEmTpGDBgtK0adMMzfXcuXNy4cIF49/i4uIkIiJC/vzzT/VvBQoUSHOh601cXJycOnVKNm3apP7t0KFDqX6/Tp06Sa5cuWTs2LGpFv36N9zpnUO9evWkePHiMnXqVON3WLx4sWzfvl3atWuXod9DROTYsWPGOFeuXFKjRg0REeMxAAAAACCn81krJxGRESNGSLdu3WT69Ony5ptvSqNGjSQ+Pl7uu+8+KV++vBw+fFh++OEHOXjwoGzcuFH9zLx586Rbt27Sv39/qVu3rhw/flwWLlwoU6dOlZo1a8r9998vb7/9tvTt21fWrVsnMTExMm/ePFmzZo1MnDhRfQudXrt27ZIWLVpI9+7dpWrVqhIaGirz58+Xw4cPS48ePdTt6tatK1OmTJEXXnhBKlSoIMWLF5dbb73V63336NFDnnjiCencubMMHTpUzp07J1OmTJEbbrhBfvnlF3W7ChUqyMiRI+X555+Xxo0byx133CFhYWHy008/SenSpWXcuHEZmkOePHnk5Zdfln79+knTpk2lZ8+eqpVTTEyMPPLIIxn6G4mI3HvvvXL8+HG59dZbJTo6Wvbt2yeTJk2SWrVqqXpvAAAAAAgKGb289d9tjH766adUuStXrjhxcXFOXFycc/nyZWfPnj3OPffc45QsWdLJkyePU6ZMGad9+/bOvHnzjJ87duyY89BDDzllypRx8ubN60RHRzt9+vRxkpKS1G0OHz7s9OvXzylWrJiTN29eJz4+3pk2bZpxP3+3ckqrRZOIOGPGjHEcx3GSkpKcBx980KlcubJToEABp3Dhws6NN97ozJkzx/iZxMREp127dk5ERIQjIqqlkre/geM4ztKlS53q1as7efPmdSpVquTMmDEjVSunv73//vtO7dq1nbCwMCcyMtJp2rSps2zZsqvOwW7l9LfZs2er+ytSpIjTq1cv5+DBg8Zt+vTp4xQoUCDVXOw5zps3z2nVqpVTvHhxJ2/evM7111/vDBw40Dl06FCavzcAAAAA5FQhjqPt4QUAAAAAwIV8VnMMAAAAAEBOxeIYAAAAAOB6LI4BAAAAAK7H4hgAAAAA4HosjgEAAAAArsfiGAAAAADgeiyOAQAAAACuFxrIBwsJCQnkw8ELX7e35thmHxzb4OXLY8txzT44Z4MXxzZ48XocnDhng1d6jy3fHAMAAAAAXI/FMQAAAADA9VgcAwAAAABcj8UxAAAAAMD1WBwDAAAAAFyPxTEAAAAAwPVYHAMAAAAAXI/FMQAAAADA9VgcAwAAAABcj8UxAAAAAMD1QrN6AoAv5Mr1z//nyZcvn5Fr2LChikeNGmXkHMdR8dmzZ43chg0bjPHcuXNVvHHjRo/3g5wtJCTE4zglJSXQ03G9iIgIYxwWFqZi+1idPHnSGF+6dMlv8wIAAMGHb44BAAAAAK7H4hgAAAAA4HohTgD3g9pb4JB1fH3YA31s9a2VIiK33nqriu2t05UqVVJxwYIFjZw+78uXLxu5K1euGONjx46puGXLlkZu9+7d6Zl2QOT0Y5sV6tWrp+KFCxcauX//+98qHjNmTMDmlBZfHtvsfFzz5MmjYv38FRF5/PHHVRwZGWnkPv74Y2M8f/58FV+4cMGXU/QpN52z+tzseQZj2YKbjq0/6CVTItnrORKsr8f231z/PbNbCZk+V189Nzhng1d6jy3fHAMAAAAAXI/FMQAAAADA9VgcAwAAAABcj1ZOyLbsOo1SpUqpePHixUaucuXKKg4NNZ/Weh2KXZOyb98+Fdv1yMWLFzfGep1z27ZtjdyUKVNUTPuYnOeuu+5ScYECBYxcYmJioKfjemXKlFHxs88+a+Tq1KmjYr02WSR1rdzmzZtVvG3bNiOXnWoXg43+2h0VFWXkhgwZouJVq1YZudWrV6v4/PnzPnn88PBwI6e/P/z5559G7uLFi5l+TGSe/V4/YMAAFdvXEJk6daqK//Wvfxm57FYPm53Zn5OGDRum4i5duhi5b7/9VsWvvfaakdPb5/nq728/H/S52p/L9NadBw8eNHLZ+ToT2ZH9d3fz+cQ3xwAAAAAA12NxDAAAAABwvRy/rTp37tzGOG/evCq2t7farXqQvdlbJB977DEVlytXzuPPHT161Bjff//9Kv7++++NnL51Lz4+3sjNmTPHGOvbuvv162fk9HY/bKvO/uwtZTExMSrevn27kZsxY0YgpuRq+fPnN8aDBg1ScevWrY2cvk3W3vZVu3ZtY3zHHXeo+MCBA0bu9OnTHu8H10bf7v70008buXbt2qn4uuuuM3K//PKLiu0tkZk9RnFxcca4Z8+eKl6+fLmR++abbzL1GLg29lbZp556SsUlS5Y0ck2aNFHxhAkTjByf8bzTP1Ppf2MRkeHDh6vY3p6sjwPx+cZ+f65WrZqK9VZ+Iubr+Ouvv27kdu7c6YfZBZeiRYuquHv37kbuiy++UPHvv/9u5IL9PZNvjgEAAAAArsfiGAAAAADgeiyOAQAAAACulyNrjvVWK507dzZyen2TXbO6bNkyFb/77rtG7siRIyo+e/askfN2OXi7HYj+mPaefP229tz02165csXj47mJ/TeaP3++iu0aJb0ewq5DOn78uIq91Uls3brVGOstCkTM2qd169YZObslCLK30qVLG+OaNWuq+MsvvzRy9usBfEOvK2vVqpWRGzhwoIrtemS93YT9+mu34dLvJzo62siNGTNGxYcOHUrvtJEOFStWVHHHjh2NnH4+ff7550buxIkTKr6Wmjb9WiTPPPOMkdNr2O33WmqOA8N+b7/99tuNsX6u2u1l9Pd6+37gXaFChVTcpk0bI6e3Mdu/f7+RW7JkiYqTk5ONnD9qT/V5ipitpW655RYjp5/Ddts/pGZf52HWrFkqbtSokZF74IEHVGy/Rwd7i0teWQAAAAAArsfiGAAAAADgejlyW7W+lcZu0xAbG6tiva2TiNmKx94ioG+d1rfhipjb/+xtWPZWPf2y6PaWvzNnzni8H32rUP/+/Y3c7t27xY3slgF6m4+RI0cauaSkJBWfO3cu3Y+hP5f0ti8iIpUqVTLG+nPklVdeMXL2sUb2pm/TEjFfKxYvXmzkgr1lQVapXr26iu3zuXDhwiq2t1V6Ox72FuywsDAV2yU4epnEgAEDjJzdDg7e2e+1U6dOVbHdbvHDDz9U8YoVK4ycr15HIyIiVFyjRg0jpz8nVq9e7ZPHQ8bo7dhEUp9/+nNGb7coIjJz5kwVU4Lmnf3aqf+dy5cvb+T27dun4lGjRhk5vQ2ev94P9WNub7O/9957VWyXzjzxxBMq1ssj8Q/99dD+7Kq3RtNb8ImY75EPPvigkRs/frwx1tc3wYBvjgEAAAAArsfiGAAAAADgeiyOAQAAAACuF+IEsKDOrn/wBbvm+NVXX1Vx7dq1jZzemkevOxIx6yiKFCni8fH0y92LiBQrVswY6/d7+fJlI6e3+8mXL5+R02tn/vWvfxk5/fL0vjpcvj7s/ji23h7DWx2i/bvpt7VrnW666SYV6+0KRFLX0en1aU2bNjVy2anmOCceW3+z6x5/+OEHY6y3BmvWrJmRS0hI8Ne0MsyXxzbQx9V+zXvzzTdV3Lt3byOnX+fBpr+unj592sjZ1xvQ69Pseir9MXbt2mXkunfvruKdO3d6nIuv5PRztn379sZYrwu122Q1aNBAxfbx8xW9VduWLVuM3OHDh1Wst3ATSf3+7gs5/dj6ij7vG264wcj9+OOPxrhgwYIqtp8/8fHxKrbbLQZadn89joyMNMabNm1Ssf3ZVW+Vec899xg5+7OsP+j1rWvXrjVyJUqUULH9XNFbxZ06dconcwm2c3bQoEEqnjhxopHTPxvZ19rQ1yz252G9Dl1EpFevXires2dPpufqb+k9tnxzDAAAAABwPRbHAAAAAADXy5GtnHT21/f6djj7ku/69gF9246IucXObgeib9Wzt+3ZWw30sZ3r16+fih955BEjp7cUWrZsmZGjlcxfvG2d1tlbWPTtnHXq1DFykydPVrF9vM6ePWuM9VZP2WkbNa6uTJkyxrhKlSrGeP/+/SpOTEwMyJzcxi6B0bfiettGbW911bfVzZs3z8ht3rzZGNevX1/FdisnfUtttWrVjJzezkvfxikikpyc7HGubqIfsxEjRhg5/f3svffeM3L+2kqt09vU2Nvp9W3y/thGjbTpz4lOnToZObvcSbdgwQJj7Kuts8FK/5z7zDPPGDl9K7W9Vfrjjz/2mPMH+5hPmDBBxVFRUUZOb9H08MMPG7lAvJ7kNPZrnl4qZn8+1rfaT5s2zcjp73V2Cyj9vVXE3Aqvb7EWEVm6dGk6Zp298M0xAAAAAMD1WBwDAAAAAFyPxTEAAAAAwPVyfM2xTa8h8lZPlJSU5Pe56DU2ImbbAbtm9sSJEypet26dX+cV7Oy2PUWLFlXxG2+8YeT0lhL280VvNSMSmOcMfEc//+677z4jZ9fk6O1eLl265N+JuYje2u7BBx80ct5a5unHwG6xNnjwYBXb9eF6SzwRke+++87j/ei1jNdff72RK1u2rIr1WjgR8/dw8/Ug9DptvcZXROS3335Tsf06Ggh6zZv9PvzTTz8FejoQkeuuu07Fdqsg+3ofFy5cUPHbb79t5Nx8zqWH/re0r6Wgnwv2NVUOHjyYqcfz1qbI/ixWqFAhFffv39/ItWnTRsV2i67HHntMxfZ1JXg+pGa/n+ltbfX6bRGRd999V8WffPKJkatVq5aKr/a5SK9nt2uXY2Ji0n0/2QXfHAMAAAAAXI/FMQAAAADA9YJuW3V2EhkZaYy7dOmiYnsryKRJk1R8/vx5/04syNnbfG655RYV29tN9OOwa9cuI/fiiy96vC2yP72VW4sWLYycvbXnrbfeUjFtunxH30anb+2y2cfjq6++UvHdd99t5OztgN7oLUm2bt1q5B544AEVz54928jpbUYaNGhg5PQ2gGfOnEn3XIJNq1atVGxvXdbPJ7v9oT/Y2zf155qdmz9/vt/ng9T0bZfR0dFeb6uXuezbt89vcwpGeinLn3/+aeT0shO71emTTz6p4scff9zIFS9eXMV2azu9TaLdMnH37t3GWC9X0bdR23PbsWOHkdPbm9qlM0hNLxcUMduZ2tvS9a3U9vuZfh6uWrXKyHXs2NEY69v59fd9EfO5Zm+Zz6745hgAAAAA4HosjgEAAAAArsfiGAAAAADgetQc+1ho6D9/0tGjRxu5qlWrqvjo0aNGbty4cf6dWJDTa95Kly5t5PT6GbvORq9JtNs8ZaS2EVnPrnssUaKEivVaJxGRbdu2GWO9Dofa8syz6/31NmoRERFGTm+dtnTpUiOnt3rx1Xlo16rprUvs6w1UqVJFxXYNut6Sxk01x/p7m4j5fmafT3qbrECw24LpLUjs45fZljXIGPv1uGbNmirWayBFzPdhEZGFCxeqODk52Q+zC176a9JLL71k5EqWLKniwoULG7kbb7xRxXZ9qf6Zym6DqF8vwj5W9uujXg9ttxTSX4Ofe+45r/eD1PT3Xv09SsSs2//oo4+MnP6+qB8fEfM58vXXXxu5ChUqGOPq1aur+PTp00ZO/xxAzTEAAAAAADkEi2MAAAAAgOuxrdrH9K0G+tZAEbOlxODBg42cvsUQGadfRn7y5MlGrnLlyh5/7rffflPxzJkzjRzba3MWe0tv48aNVWxvp//555+N8alTp/w3MRfT27fkz5/fyB06dEjFL7zwgpGzt2X5gv38OH78uIp37txp5PRt1fYWNX2L2IEDB3w4w+zNPofKly+vYnvLeiBeO/XjOWXKFCOnbw/csGGDkQtEaymkbqE1cOBAFdtbcy9cuGCM9fYytNbLGP1cXL9+vZHT26/ZbZf0be92y8uoqCgVx8TEGDn9s5f9GmuXuJUqVSrNWMT8/LV27Vojx3Pg6vTzTd8+L2KWldnrkh49eqjY3mqvH3f7HN2zZ48x1sum7BIcvR3i3r17jVx2/ZzNN8cAAAAAANdjcQwAAAAAcD0WxwAAAAAA16Pm+BrZdTVPPPGEiu39+/oe/S+++MK/Ewtydk2D3q6padOmRk6vg9m4caOR69Wrl4rtmgrkLPZzomfPniq2a9zs+nK7ZhKZY78e3nTTTSouWLCgkdu/f7+K7folf7DnptfQ1q1b18jpbWjs9hZ66xI3sesJ9bo2+9jefPPNKl60aJGRy+zfzz6/o6Oj03w8+zHsFn2c64Fh1+rXq1fP4223bNlijPXWM8g8+1o2+ti+zobdjs0T+3XAWxvNESNGGOOuXbuqOCkpycjpn4m5Bk/G6bW7dpss/T2sRYsWRk4/fnb7NZ19fY0dO3YYY/0cts/12267TcVz5841cnYbt+yCb44BAAAAAK7H4hgAAAAA4HosjgEAAAAArkfN8TXSe16KiHTu3FnFf/75p5HT62Kz6z77nKJSpUrGeNiwYSq260u3bt2q4nvvvdfIJSQkqDi79lsTSV3no4/pAfgXvd+iiEi1atVUnJiYaOQ2b94ckDm5jV0XWq5cORXbNb96zVJycrJf5hMeHq5ivWejiMjrr7+uYr1+VcT8PXbt2mXk9P7MbmLXo/3+++8qrl69upEbMGCAimNjY43cDz/84PEx9OOl9ykXSd1nWa+ZtM99/foROaWvZjDQ35fi4uKMnH5s7brvN9980xjz+Sj7ss8f/ViePXvWyFWoUMEY65+XV69ebeR+++03X03RlfTjsGDBAiPXoUMHFd9yyy1GTj8m9nV31qxZo2K7X7x93Ra9ztg+9/Wct9fx7IRvjgEAAAAArsfiGAAAAADgemyrziC7rceUKVOMsb5lYPv27UbObmmBjNH/9k8++aSRy5cvn4oPHz5s5J566ikV79y508hlp7Ye9nNL35Jqz1PfDo6/VK1a1Rjr56LeNkhE5Pz58wGZk9vYW29vuOEGFdtbp9evX69iX5UG2Fu2unXrpmL7NUPf+mWXLZw7d07Fdts9e+ugW5w4ccIYDx8+XMUPP/ywkdOPe7NmzYxcx44dVWy/rumtYOxWiEuXLjXG+nY8exuu/jyw28vAf/TzX2+TKGKWO9ntvNauXWuM2fqec+jHvEmTJkauTp06xlgvNfz888+NnFtb5PmD/V7bp08fFZcpU8bIlS1bVsV6qYyIyMmTJ1Vsv+/Z5Yv6a7B9/pYqVUrFtWrVMnIrV660p58t8M0xAAAAAMD1WBwDAAAAAFyPxTEAAAAAwPWoOU4HvQXJc889Z+T01k0iZk3Fyy+/bOQuXrzoh9kFL7sOMD4+XsUtW7Y0cnrdi14nISJy7NgxFdu1EPpjZKTOyZ6bztv92DWZ+fPnV/Edd9xh5PS6kZ9//tnI0b7pL/px6N69u5HT27vo7bzgP3a7psjISBVHREQYOb39j11vrz+/7fNJf4wGDRoYuRdeeMEY169fX8V2PbLOW03/119/beTcWhtnH4dffvlFxXaLvBIlSqi4UKFCRk5v7WQ/J/TrLGzbts3I2S2ZKleurGL9mhMi5jUFkpKSBIGhH4dOnToZOf212r4uCNfQyLn0zzT2MS9SpIgx1mvLN27caOTc+roaCPq6xH4dtcc6b5+P7Va1ui+//NIY6+ukoUOHGjm9RVR2auvEN8cAAAAAANdjcQwAAAAAcD22VadDVFSUih944AEjZ2+v1be/fvLJJ/6dmMvcdNNNKr7uuuuMnH5ZeXuLZs2aNVV89OhRI6dvXba3VtrbfPTH8LaNLzTUPK30rYPNmzc3cnq7i0qVKhk5fRv+8uXLjZx++fuPPvpI3Er/W9tbbPVjYrdRy04tvIKJXTqin0N6CYGISIcOHVR84MABI7dmzRoVFy1a1Mh16dJFxfb5ZG/Ttbd56/TngN3CYsKECSrevXu3kaPNTGr2cdePp/0eqbc4tI+PvkXzatssq1Wr5vF+9PnYbdzgP3p7NPs9Wj/f3n33XSPnbYsmsje9Tc/tt99u5C5cuGCMFy9erGL7dRXZj7f3Ojt35swZFU+ePNnI6a8L9erVM3K33nqrihcsWJDux/c3vjkGAAAAALgei2MAAAAAgOuxOAYAAAAAuB41x2mw65eef/55FRcsWNDI7du3zxjrNcnUNV4bu95Ar+c+ffq0kdPbhZQuXdrIPfrooyq2W47oP2e3HbCPn94ayK5j029rty7Rn08VK1Y0cnrLGrs9k14HuXr1aiPn5jpjXcOGDVWs1yCKmMfk119/NXLUjfqHXTu4a9cuFdetW9fI6TWJI0aMMHL6OWu/Huu1/3ZrNG8uX75sjPVWIiNHjjRyeo0/r+PXxj7X9HFGWtLZtct6Kyf7MbZs2aJi+z0avmMfkzvvvFPF4eHhRk6vA//mm2+MHK/HOZd+rQ/787HdVjMxMVHFtG4KXvpxFhGZPXu2isuWLWvkbr75ZhV/++23Rs7+nB9IfHMMAAAAAHA9FscAAAAAANdjW3Ua4uPjjXHHjh1VfO7cOSNnb8fbtm2b/ybmcps3b1axva24U6dOKtZbb9ljve2AiLkNSN+uKeJ9y6a9BVtvWXD27Fkjp9/v4cOHjdzOnTtVfOrUKSM3c+ZMFdvbqt3K3sY3ceJEFUdGRhq5n376ScU7duzw67yQNn27dJUqVYycvs3aPvfsdmzpZW/T1bdy6s8HEZH77rtPxXZbEbZSZz/2ua8/n+z2eWzfDAz7mNxyyy0qtsshkpKSVMznpJzLPuZ33HGHiu3XX3tbtd2yD8HJLpPQP7/a5W/R0dEqvvHGG42cXn4R6NILvjkGAAAAALgei2MAAAAAgOuxOAYAAAAAuB41x/9Pr3F76aWXjJzemmfr1q1Gzr70eEZaUyBjkpOTVTx69GgjN3nyZBW3b9/eyOm1aXo7JhGz3kGPRVLXsemtKfRWISIiX331lYqPHDli5LZv357m7yBi1uScP3/eyOl1j9RA/sVuk1WpUiUV26163nnnHY85BIZeZ9ijRw8j9+KLL6pYv2aASOo2MDq99shuHXX8+HFj/O9//zvNWMQ8Tzm/sj+71lG/zoP92nns2DEV0ybIf+zrcpQrV07F9muu/p6pHzvkLPb5pF/Pwz4PIyIijLF+jRf7fEbwOnr0qIrtNm6tW7dWcVxcnJHT11fUHAMAAAAAEGAsjgEAAAAArufabdX2diD9cvR6OwIRc+ve+PHjjZzdmgeBYbfUSkhIULG+xRrBxd5Gq7fgsbfGfvrppwGZE9JHP0dFRO69914VT58+3cjdc889Ki5atKiR+/XXX1X83//+18itWLHCGOtbp2npk7PZ7b70EiZ9G7WIuY3P3r7JNmvfsf+W+uch+7zVt99S5pJz2eeT3qZnyJAhRs5uealvoV2zZo2R00twvJ2j9md3ShlzFvs9u3r16iq2XzP0MshAl2LwzTEAAAAAwPVYHAMAAAAAXI/FMQAAAADA9Vxbc2y3hHniiSdUnC9fPiOn1zXqLXtEqF8CAsmuO6lRo0YWzQTXSm/7sWzZMiNnjwH7vXbt2rUq3rdvn5GbM2eOimkZ4z/2dR70awd06dLFyM2cOdPjzyHnsM/DH3/8UcV2m55GjRoZ4/Xr16vYbvuks89Zfcxn7pzNrhH/+OOPPd724sWLKg70tSP45hgAAAAA4HosjgEAAAAArhfiBHCPQlZvb9If327XtHjxYhWHh4cbuaFDh6p46tSpRi6nbvHw9byz+tjiHxzb4OXLY8txzT44ZzNOb+li/77ZaduuW4+t3XorGFup8XpsCg01KzXLly9vjPfs2aPi7HSO2tx6zmaF3Llzq1hv3SRivmb4qv1beo8t3xwDAAAAAFyPxTEAAAAAwPVYHAMAAAAAXM9VrZz0veZ2LYTeImbVqlVGTr/UeE6tMQYAIFjYLUGQvQRjjTG8s+tCd+3alUUzQU6hv457a+8VaHxzDAAAAABwPRbHAAAAAADXc1UrJ51++XCbvV0rGLdSc6n64MWxDV60DglOnLPBi2MbvHg9Dk6cs8GLVk4AAAAAAKQTi2MAAAAAgOuxOAYAAAAAuF5Aa44BAAAAAMiO+OYYAAAAAOB6LI4BAAAAAK7H4hgAAAAA4HosjgEAAAAArsfiGAAAAADgeiyOAQAAAACux+IYAAAAAOB6LI4BAAAAAK7H4hgAAAAA4Hr/B058sBzZ2/cDAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. üìä Evaluation Metrics\n",
        "def mse(imgs, recons):\n",
        "    return F.mse_loss(recons, imgs).item()\n",
        "\n",
        "def psnr(imgs, recons):\n",
        "    mse_val = mse(imgs, recons)\n",
        "    if mse_val == 0: return 100\n",
        "    return 20 * np.log10(1.0 / np.sqrt(mse_val))\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_loss = 0\n",
        "    total_psnr = 0\n",
        "    for imgs, _ in test_loader:\n",
        "        imgs = imgs.view(imgs.size(0), -1).to(device)\n",
        "        recons, _ = model(imgs)\n",
        "        test_loss += criterion(recons, imgs).item()\n",
        "        total_psnr += psnr(imgs, recons)\n",
        "    test_loss /= len(test_loader)\n",
        "    total_psnr /= len(test_loader)\n",
        "\n",
        "print(f\"Test MSE: {test_loss:.4f}, Average PSNR: {total_psnr:.2f} dB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKYyAaG8xuLZ",
        "outputId": "3f16bfe5-3cdc-4ca8-b49e-5621410b6c19"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE: 0.0068, Average PSNR: 21.69 dB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. ‚úÖ Conclusions\n",
        "# - Deep autoencoder successfully compresses MNIST from 784D to 30D.\n",
        "# - Reconstructions preserve digit structure, outperforming PCA qualitatively.\n",
        "# - Codes (latent embeddings) can be visualized or used for retrieval/classification tasks.\n"
      ],
      "metadata": {
        "id": "uiRybWHIxyQ5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä Results & Analysis ‚Äì Deep Autoencoder (Replication of Hinton & Salakhutdinov, 2006)\n",
        "\n",
        "## üîÑ Training Performance\n",
        "- The model trained stably on **MNIST** for multiple epochs.  \n",
        "- Final evaluation gave:  \n",
        "  - **Test MSE:** ‚âà **0.0068**  \n",
        "  - **Average PSNR:** ‚âà **21.7 dB**  \n",
        "- These values indicate that the autoencoder effectively reconstructed digits with **low reconstruction error** and **reasonable perceptual quality**.\n",
        "\n",
        "---\n",
        "\n",
        "## üñºÔ∏è Reconstructions\n",
        "- **Top row:** Original MNIST digits.  \n",
        "- **Bottom row:** Reconstructions from the 30-dimensional code layer.  \n",
        "- Observations:  \n",
        "  - Reconstructions preserve the **global structure** of digits (shapes and strokes are intact).  \n",
        "  - Some fine-grained details are **slightly blurred**, but digits remain easily recognizable.  \n",
        "  - Confirms that the autoencoder compressed **784D ‚Üí 30D** without losing essential information.  \n",
        "\n",
        "---\n",
        "\n",
        "## üìà Quantitative Evaluation\n",
        "- **MSE (0.0068):** Low pixel-wise reconstruction error, showing that inputs and outputs are close in raw pixel space.  \n",
        "- **PSNR (21.7 dB):** A solid result for lossy image compression‚Äîvalues in this range suggest reconstructions are **visually faithful**, though not perfect.  \n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Conclusions\n",
        "- **Dimensionality Reduction:** Successfully compresses MNIST images from **784 dimensions to 30 dimensions**.  \n",
        "- **Reconstruction Quality:** Outperforms PCA qualitatively, capturing nonlinear structures.  \n",
        "- **Representation Learning:** Latent codes ($z$) can be used for **visualization, retrieval, or classification**.  \n",
        "- **Trade-off:** Reconstructions are slightly smoother than originals, but this is expected given the compact representation.  \n",
        "\n",
        "**Impact:** These results replicate the findings of Hinton & Salakhutdinov (2006), demonstrating that **deep autoencoders are powerful nonlinear dimensionality reduction tools** that surpass PCA in both reconstruction accuracy and representational usefulness.\n"
      ],
      "metadata": {
        "id": "hZJzA_hpzBg4"
      }
    }
  ]
}