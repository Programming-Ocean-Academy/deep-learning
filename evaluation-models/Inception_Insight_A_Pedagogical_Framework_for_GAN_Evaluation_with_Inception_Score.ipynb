{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Inception Insight — A Didactic DCGAN + Inception Score (IS) Evaluation Suite (PyTorch)\n",
        "=====================================================================================\n",
        "An end-to-end teaching project that trains a DCGAN on CIFAR-10 and evaluates the\n",
        "**Inception Score (IS)** across epochs. Includes:\n",
        "\n",
        "• Dataset: CIFAR-10 (32×32 RGB)\n",
        "• Model: DCGAN (configurable) — generator & discriminator\n",
        "• Evaluation: Inception Score (splits, mean ± std) with InceptionV3 logits\n",
        "• Visuals: Loss curves, IS curve, per-epoch sample grids, optional t-SNE of features\n",
        "• Artifacts: CSV logs, animated GIF timeline of samples\n",
        "• Epochs: configurable (5/10/20) for pedagogy\n",
        "\n",
        "Run\n",
        "----\n",
        "python inception_score_gan.py \\\n",
        "  --data_root ./data \\\n",
        "  --outdir ./outputs_is \\\n",
        "  --epochs 10 \\\n",
        "  --batch_size 128 \\\n",
        "  --is_every 1 \\\n",
        "  --num_is_samples 5000 \\\n",
        "  --is_splits 10\n",
        "\n",
        "Optional flags: --epochs {5,10,20}, --lr 2e-4, --nz 128, --ngf 64, --ndf 64, --device cuda\n",
        "\n",
        "Notes\n",
        "-----\n",
        "• Inception Score uses ImageNet-pretrained InceptionV3 logits (softmax) to\n",
        "  measure both sample quality and diversity. Higher IS is better.\n",
        "• We compute IS over generated samples in splits, reporting mean ± std.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "eYHmeQb_bkTs",
        "outputId": "4836c5a0-a15a-45be-c3df-7e162cdb66a6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nInception Insight — A Didactic DCGAN + Inception Score (IS) Evaluation Suite (PyTorch)\\n=====================================================================================\\nAn end-to-end teaching project that trains a DCGAN on CIFAR-10 and evaluates the\\n**Inception Score (IS)** across epochs. Includes:\\n\\n• Dataset: CIFAR-10 (32×32 RGB)\\n• Model: DCGAN (configurable) — generator & discriminator\\n• Evaluation: Inception Score (splits, mean ± std) with InceptionV3 logits\\n• Visuals: Loss curves, IS curve, per-epoch sample grids, optional t-SNE of features\\n• Artifacts: CSV logs, animated GIF timeline of samples\\n• Epochs: configurable (5/10/20) for pedagogy\\n\\nRun\\n----\\npython inception_score_gan.py   --data_root ./data   --outdir ./outputs_is   --epochs 10   --batch_size 128   --is_every 1   --num_is_samples 5000   --is_splits 10\\n\\nOptional flags: --epochs {5,10,20}, --lr 2e-4, --nz 128, --ngf 64, --ndf 64, --device cuda\\n\\nNotes\\n-----\\n• Inception Score uses ImageNet-pretrained InceptionV3 logits (softmax) to\\n  measure both sample quality and diversity. Higher IS is better.\\n• We compute IS over generated samples in splits, reporting mean ± std.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"sample\")"
      ],
      "metadata": {
        "id": "3JSS9AWsb8K4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_kR2sFgbb0G",
        "outputId": "62365a1e-afa6-41ea-ae2c-4583a41f7f08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sample/inception_score_gan.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile sample/inception_score_gan.py\n",
        "import os\n",
        "import math\n",
        "import argparse\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, List\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, utils as vutils, models\n",
        "from torchvision.models import Inception_V3_Weights\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "\n",
        "try:\n",
        "    from sklearn.manifold import TSNE\n",
        "    _HAVE_SK = True\n",
        "except Exception:\n",
        "    _HAVE_SK = False\n",
        "\n",
        "# ------------------------------\n",
        "# Reproducibility\n",
        "# ------------------------------\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# DCGAN Models\n",
        "# ------------------------------\n",
        "\n",
        "class DCGANGenerator(nn.Module):\n",
        "    def __init__(self, nz=128, ngf=64, nc=3):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf, nc, 3, 1, 1, bias=False),\n",
        "            nn.Tanh(),  # [-1, 1]\n",
        "        )\n",
        "    def forward(self, z):\n",
        "        return self.main(z)\n",
        "\n",
        "class DCGANDiscriminator(nn.Module):\n",
        "    def __init__(self, ndf=64, nc=3):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.main(x).squeeze(1)\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# InceptionV3 logits extractor for IS\n",
        "# ------------------------------\n",
        "\n",
        "class InceptionV3Logits(nn.Module):\n",
        "    \"\"\"Pretrained InceptionV3 that outputs 1000-d logits.\n",
        "    Uses torchvision's official weights + preprocessing transforms.\n",
        "    \"\"\"\n",
        "    def __init__(self, device: torch.device):\n",
        "        super().__init__()\n",
        "        weights = Inception_V3_Weights.IMAGENET1K_V1\n",
        "        self.transforms = weights.transforms()  # resize 299, center-crop, normalize\n",
        "        self.model = models.inception_v3(weights=weights, aux_logits=False).to(device).eval()\n",
        "        for p in self.model.parameters():\n",
        "            p.requires_grad_(False)\n",
        "        self.device = device\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def logits(self, imgs01: torch.Tensor, batch_size: int = 64) -> torch.Tensor:\n",
        "        \"\"\"imgs01 in [0,1], shape (N,3,H,W). Returns (N,1000) logits.\"\"\"\n",
        "        outs = []\n",
        "        n = imgs01.size(0)\n",
        "        for i in range(0, n, batch_size):\n",
        "            b = imgs01[i:i+batch_size].cpu()\n",
        "            proc = torch.stack([self.transforms(x) for x in b]).to(self.device)\n",
        "            y = self.model(proc)  # (B,1000)\n",
        "            outs.append(y.detach().cpu())\n",
        "        return torch.cat(outs, dim=0)\n",
        "\n",
        "\n",
        "def inception_score_from_logits(logits: torch.Tensor, splits: int = 10) -> Tuple[float, float]:\n",
        "    \"\"\"Compute Inception Score from logits (ImageNet classes).\n",
        "    Returns (mean, std) across splits.\n",
        "    \"\"\"\n",
        "    probs = torch.softmax(logits, dim=1)  # (N,1000)\n",
        "    N = probs.size(0)\n",
        "    assert splits >= 1 and N >= splits, \"Invalid splits/N for IS\"\n",
        "    sizes = [N // splits] * splits\n",
        "    sizes[-1] += N - sum(sizes)  # remainder to last split\n",
        "\n",
        "    scores = []\n",
        "    start = 0\n",
        "    for s in sizes:\n",
        "        p_yx = probs[start:start+s]                       # (s,1000)\n",
        "        p_y = p_yx.mean(dim=0, keepdim=True)              # (1,1000)\n",
        "        kl = p_yx * (torch.log(p_yx + 1e-10) - torch.log(p_y + 1e-10))\n",
        "        kl_mean = kl.sum(dim=1).mean()                    # scalar\n",
        "        scores.append(torch.exp(kl_mean).item())\n",
        "        start += s\n",
        "    scores = np.array(scores)\n",
        "    return float(scores.mean()), float(scores.std())\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Dataset & Utilities\n",
        "# ------------------------------\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    data_root: str = \"./data\"\n",
        "    outdir: str = \"./outputs_is\"\n",
        "    batch_size: int = 128\n",
        "    workers: int = 2\n",
        "    epochs: int = 10\n",
        "    lr: float = 2e-4\n",
        "    beta1: float = 0.5\n",
        "    nz: int = 128\n",
        "    ngf: int = 64\n",
        "    ndf: int = 64\n",
        "    is_every: int = 1\n",
        "    num_is_samples: int = 5000\n",
        "    is_splits: int = 10\n",
        "    seed: int = 42\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "def get_cifar10_loader(cfg: TrainConfig):\n",
        "    tf_train = transforms.Compose([\n",
        "        transforms.Resize(32),\n",
        "        transforms.CenterCrop(32),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "    train_set = datasets.CIFAR10(root=cfg.data_root, train=True, download=True, transform=tf_train)\n",
        "    train_loader = DataLoader(train_set, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.workers, drop_last=True)\n",
        "    return train_loader\n",
        "\n",
        "\n",
        "def denorm_to_01(x: torch.Tensor) -> torch.Tensor:\n",
        "    return x.add(1).div(2).clamp(0, 1)\n",
        "\n",
        "\n",
        "def save_image_grid(tensor: torch.Tensor, path: str, nrow: int = 8):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    grid = vutils.make_grid(tensor, nrow=nrow, padding=2)\n",
        "    vutils.save_image(grid, path)\n",
        "\n",
        "\n",
        "def plot_curves(curves: dict, path: str, title: str, ylabel: str):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    for k, v in curves.items():\n",
        "        xs = list(range(1, len(v)+1))\n",
        "        plt.plot(xs, v, label=k)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def save_csv(path: str, header: List[str], rows: List[List]):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    with open(path, 'w') as f:\n",
        "        f.write(','.join(header) + '\\n')\n",
        "        for r in rows:\n",
        "            f.write(','.join(map(str, r)) + '\\n')\n",
        "\n",
        "\n",
        "def make_gif_from_folder(folder: str, out_path: str, fps: int = 4):\n",
        "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "    frames = []\n",
        "    if not os.path.isdir(folder):\n",
        "        return\n",
        "    for name in sorted(os.listdir(folder)):\n",
        "        if name.lower().endswith('.png'):\n",
        "            frames.append(imageio.v2.imread(os.path.join(folder, name)))\n",
        "    if frames:\n",
        "        imageio.mimsave(out_path, frames, fps=fps)\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# IS Evaluator\n",
        "# ------------------------------\n",
        "\n",
        "class ISEvaluator:\n",
        "    def __init__(self, device: torch.device, outdir: str):\n",
        "        self.device = device\n",
        "        self.extractor = InceptionV3Logits(device)\n",
        "        self.outdir = outdir\n",
        "        os.makedirs(self.outdir, exist_ok=True)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def compute_is(self, generator: nn.Module, nz: int, num_samples: int = 5000, splits: int = 10, batch: int = 128) -> Tuple[float, float]:\n",
        "        logits_all = []\n",
        "        for _ in range(math.ceil(num_samples / batch)):\n",
        "            bs = min(batch, num_samples - len(logits_all)*batch)\n",
        "            z = torch.randn(bs, nz, 1, 1, device=self.extractor.device)\n",
        "            fake = generator(z)  # [-1,1]\n",
        "            fake01 = denorm_to_01(fake)\n",
        "            logits = self.extractor.logits(fake01)  # (bs,1000)\n",
        "            logits_all.append(logits)\n",
        "        logits_all = torch.cat(logits_all, dim=0)[:num_samples]\n",
        "        mean, std = inception_score_from_logits(logits_all, splits=splits)\n",
        "        return mean, std\n",
        "\n",
        "    def tsne_plot(self, generator: nn.Module, nz: int, path: str, num_fake: int = 1000):\n",
        "        if not _HAVE_SK:\n",
        "            return\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(num_fake, nz, 1, 1, device=self.extractor.device)\n",
        "            fake = generator(z)\n",
        "            fake01 = denorm_to_01(fake)\n",
        "            # Use Inception features before logits for t-SNE: swap classifier for Identity\n",
        "            feats_model = models.inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1, aux_logits=False)\n",
        "            feats_model.fc = nn.Identity()\n",
        "            feats_model = feats_model.to(self.extractor.device).eval()\n",
        "            proc = torch.stack([self.extractor.transforms(x.cpu()) for x in fake01]).to(self.extractor.device)\n",
        "            feats = feats_model(proc).detach().cpu().numpy()\n",
        "        tsne = TSNE(n_components=2, init=\"random\", random_state=42, perplexity=30)\n",
        "        emb = tsne.fit_transform(feats)\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        plt.figure(figsize=(6,6))\n",
        "        plt.scatter(emb[:,0], emb[:,1], s=6, alpha=0.6)\n",
        "        plt.title(\"t-SNE of Inception Features (Fake Only)\")\n",
        "        plt.tight_layout(); plt.savefig(path); plt.close()\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Trainer\n",
        "# ------------------------------\n",
        "\n",
        "class GANTrainer:\n",
        "    def __init__(self, cfg: TrainConfig):\n",
        "        self.cfg = cfg\n",
        "        self.device = torch.device(cfg.device)\n",
        "        set_seed(cfg.seed)\n",
        "        os.makedirs(cfg.outdir, exist_ok=True)\n",
        "\n",
        "        # Data\n",
        "        self.train_loader = get_cifar10_loader(cfg)\n",
        "\n",
        "        # Models\n",
        "        self.netG = DCGANGenerator(cfg.nz, cfg.ngf).to(self.device)\n",
        "        self.netD = DCGANDiscriminator(cfg.ndf).to(self.device)\n",
        "        self._init_weights()\n",
        "\n",
        "        # Loss/Opt\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "        self.optG = optim.Adam(self.netG.parameters(), lr=cfg.lr, betas=(cfg.beta1, 0.999))\n",
        "        self.optD = optim.Adam(self.netD.parameters(), lr=cfg.lr, betas=(cfg.beta1, 0.999))\n",
        "\n",
        "        # Fixed noise for grids\n",
        "        self.fixed_z = torch.randn(64, cfg.nz, 1, 1, device=self.device)\n",
        "\n",
        "        # IS evaluator\n",
        "        self.is_eval = ISEvaluator(self.device, cfg.outdir)\n",
        "\n",
        "        # Logs\n",
        "        self.hist_G: List[float] = []\n",
        "        self.hist_D: List[float] = []\n",
        "        self.hist_IS: List[float] = []\n",
        "        self.hist_IS_std: List[float] = []\n",
        "\n",
        "    def _init_weights(self):\n",
        "        def weights_init(m):\n",
        "            cname = m.__class__.__name__\n",
        "            if cname.find('Conv') != -1:\n",
        "                nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "            elif cname.find('BatchNorm') != -1:\n",
        "                nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "                nn.init.constant_(m.bias.data, 0)\n",
        "        self.netG.apply(weights_init)\n",
        "        self.netD.apply(weights_init)\n",
        "\n",
        "    def train_epoch(self, epoch: int):\n",
        "        self.netG.train(); self.netD.train()\n",
        "        running_G, running_D = 0.0, 0.0\n",
        "        for i, (imgs, _) in enumerate(self.train_loader):\n",
        "            b = imgs.size(0)\n",
        "            real = imgs.to(self.device)\n",
        "            z = torch.randn(b, self.cfg.nz, 1, 1, device=self.device)\n",
        "            fake = self.netG(z)\n",
        "\n",
        "            # D update\n",
        "            self.optD.zero_grad()\n",
        "            pred_real = self.netD(real)\n",
        "            pred_fake = self.netD(fake.detach())\n",
        "            loss_D = self.criterion(pred_real, torch.ones_like(pred_real)) + \\\n",
        "                     self.criterion(pred_fake, torch.zeros_like(pred_fake))\n",
        "            loss_D.backward(); self.optD.step()\n",
        "\n",
        "            # G update\n",
        "            self.optG.zero_grad()\n",
        "            pred_fake2 = self.netD(fake)\n",
        "            loss_G = self.criterion(pred_fake2, torch.ones_like(pred_fake2))\n",
        "            loss_G.backward(); self.optG.step()\n",
        "\n",
        "            running_G += loss_G.item(); running_D += loss_D.item()\n",
        "            if (i+1) % 100 == 0:\n",
        "                print(f\"Epoch {epoch:03d} [{i+1:04d}/{len(self.train_loader)}]  D: {loss_D.item():.3f}  G: {loss_G.item():.3f}\")\n",
        "\n",
        "        self.hist_G.append(running_G / len(self.train_loader))\n",
        "        self.hist_D.append(running_D / len(self.train_loader))\n",
        "\n",
        "        # Save sample grid for the epoch\n",
        "        with torch.no_grad():\n",
        "            sample = self.netG(self.fixed_z)\n",
        "            sample01 = denorm_to_01(sample)\n",
        "            save_image_grid(sample01, os.path.join(self.cfg.outdir, f\"samples/epoch_{epoch:03d}.png\"), nrow=8)\n",
        "\n",
        "    def evaluate_is(self, epoch: int):\n",
        "        mean, std = self.is_eval.compute_is(self.netG, self.cfg.nz, num_samples=self.cfg.num_is_samples,\n",
        "                                            splits=self.cfg.is_splits)\n",
        "        self.hist_IS.append(mean); self.hist_IS_std.append(std)\n",
        "        print(f\"[IS] Epoch {epoch:03d}  IS = {mean:.2f} ± {std:.2f}  (splits={self.cfg.is_splits})\")\n",
        "\n",
        "    def post_plots(self):\n",
        "        # Loss curves\n",
        "        plot_curves({\"G\": self.hist_G, \"D\": self.hist_D}, os.path.join(self.cfg.outdir, \"curves/loss_curves.png\"),\n",
        "                    title=\"GAN Loss Curves\", ylabel=\"Loss\")\n",
        "        # Inception Score curve\n",
        "        if len(self.hist_IS) > 0:\n",
        "            os.makedirs(os.path.join(self.cfg.outdir, \"curves\"), exist_ok=True)\n",
        "            plt.figure(figsize=(7,4))\n",
        "            xs = list(range(1, len(self.hist_IS)+1))\n",
        "            plt.errorbar(xs, self.hist_IS, yerr=self.hist_IS_std, fmt='-o')\n",
        "            plt.title(\"Inception Score over Epochs\")\n",
        "            plt.xlabel(\"Epoch\"); plt.ylabel(\"IS (higher is better)\")\n",
        "            plt.tight_layout(); plt.savefig(os.path.join(self.cfg.outdir, \"curves/is_curve.png\")); plt.close()\n",
        "        # Save numeric logs\n",
        "        save_csv(os.path.join(self.cfg.outdir, \"logs/losses.csv\"), [\"epoch\",\"G\",\"D\"],\n",
        "                 [[i+1, self.hist_G[i], self.hist_D[i]] for i in range(len(self.hist_G))])\n",
        "        if len(self.hist_IS) > 0:\n",
        "            save_csv(os.path.join(self.cfg.outdir, \"logs/is.csv\"), [\"epoch\",\"is_mean\",\"is_std\"],\n",
        "                     [[(i+1)*self.cfg.is_every, self.hist_IS[i], self.hist_IS_std[i]] for i in range(len(self.hist_IS))])\n",
        "        # Animated GIF\n",
        "        make_gif_from_folder(os.path.join(self.cfg.outdir, \"samples\"), os.path.join(self.cfg.outdir, \"samples/timeline.gif\"), fps=3)\n",
        "        # Optional t-SNE of generated features\n",
        "        try:\n",
        "            self.is_eval.tsne_plot(self.netG, self.cfg.nz, os.path.join(self.cfg.outdir, \"curves/tsne_fake_features.png\"))\n",
        "        except Exception as e:\n",
        "            print(f\"t-SNE plot skipped: {e}\")\n",
        "\n",
        "    def run(self):\n",
        "        for epoch in range(1, self.cfg.epochs + 1):\n",
        "            self.train_epoch(epoch)\n",
        "            if (epoch % self.cfg.is_every) == 0:\n",
        "                self.evaluate_is(epoch)\n",
        "        self.post_plots()\n",
        "        print(\"\\nArtifacts saved:\")\n",
        "        print(\" - Sample grids:\", os.path.join(self.cfg.outdir, \"samples/epoch_###.png\"))\n",
        "        print(\" - Sample animation:\", os.path.join(self.cfg.outdir, \"samples/timeline.gif\"))\n",
        "        print(\" - Loss curves:\", os.path.join(self.cfg.outdir, \"curves/loss_curves.png\"))\n",
        "        print(\" - IS curve:\", os.path.join(self.cfg.outdir, \"curves/is_curve.png\"))\n",
        "        print(\" - Logs (CSV):\", os.path.join(self.cfg.outdir, \"logs/\"))\n",
        "        print(\" - t-SNE (if available):\", os.path.join(self.cfg.outdir, \"curves/tsne_fake_features.png\"))\n",
        "        print(\"Training complete. Outputs saved to:\", self.cfg.outdir)\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Main\n",
        "# ------------------------------\n",
        "\n",
        "def parse_args() -> TrainConfig:\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument('--data_root', type=str, default='./data')\n",
        "    p.add_argument('--outdir', type=str, default='./outputs_is')\n",
        "    p.add_argument('--batch_size', type=int, default=128)\n",
        "    p.add_argument('--workers', type=int, default=2)\n",
        "    p.add_argument('--epochs', type=int, default=10)\n",
        "    p.add_argument('--lr', type=float, default=2e-4)\n",
        "    p.add_argument('--beta1', type=float, default=0.5)\n",
        "    p.add_argument('--nz', type=int, default=128)\n",
        "    p.add_argument('--ngf', type=int, default=64)\n",
        "    p.add_argument('--ndf', type=int, default=64)\n",
        "    p.add_argument('--is_every', type=int, default=1)\n",
        "    p.add_argument('--num_is_samples', type=int, default=5000)\n",
        "    p.add_argument('--is_splits', type=int, default=10)\n",
        "    p.add_argument('--seed', type=int, default=42)\n",
        "    p.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    args = p.parse_args(args=None if __name__ == '__main__' else [])\n",
        "    return TrainConfig(**vars(args))\n",
        "\n",
        "\n",
        "def main():\n",
        "    cfg = parse_args()\n",
        "    print(\"\\nInception Insight — DCGAN + Inception Score Evaluation Suite (PyTorch)\")\n",
        "    print(\"Config:\", cfg)\n",
        "    trainer = GANTrainer(cfg)\n",
        "    trainer.run()\n",
        "\n",
        "\n",
        "    if __name__ == '__main__':\n",
        "        main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python sample/inception_score_gan.py \\\n",
        "  --epochs 10 \\\n",
        "  --is_every 1 \\\n",
        "  --num_is_samples 5000 \\\n",
        "  --is_splits 10 \\\n",
        "  --outdir ./outputs_is"
      ],
      "metadata": {
        "id": "qenM3tqHcSS7"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}