{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "Fréchet Frontier — A Didactic DCGAN + FID Evaluation Suite (PyTorch)\n",
        "====================================================================\n",
        "An end-to-end project that *teaches* how to compute and use **FID (Fréchet Inception\n",
        "Distance)** to evaluate a generative model. Includes a clean DCGAN, a numerically-\n",
        "stable FID implementation using pretrained InceptionV3 features, cached real-data\n",
        "statistics, and rich visualizations.\n",
        "\n",
        "• Dataset: CIFAR-10 (32×32 RGB)\n",
        "• Model: DCGAN (configurable) — generator & discriminator\n",
        "• Evaluation: FID over training (per-epoch or every k epochs)\n",
        "• Visuals: Loss curves, FID curve, sample grids per epoch, t-SNE of features\n",
        "• Epochs: configurable (5/10/20) for pedagogy\n",
        "\n",
        "Run\n",
        "----\n",
        "python fid_gan_project.py \\\n",
        "  --data_root ./data \\\n",
        "  --outdir ./outputs \\\n",
        "  --epochs 10 \\\n",
        "  --batch_size 128 \\\n",
        "  --fid_every 1 \\\n",
        "  --num_fid_samples 5000\n",
        "\n",
        "Optional flags: --epochs {5,10,20}, --lr 2e-4, --nz 128, --ngf 64, --ndf 64, --device cuda\n",
        "\n",
        "Notes\n",
        "-----\n",
        "• FID is computed between *Inception features* of real vs generated images.\n",
        "• We cache real CIFAR-10 stats to speed up repeated runs.\n",
        "• For teaching: code is thoroughly structured into classes & utilities.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "EHLBmxHiXmlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import argparse\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, List\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms, utils as vutils, models\n",
        "from torchvision.models import Inception_V3_Weights\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    from sklearn.manifold import TSNE\n",
        "    _HAVE_SK = True\n",
        "except Exception:\n",
        "    _HAVE_SK = False"
      ],
      "metadata": {
        "id": "AsuiYAkmXse9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# Reproducibility\n",
        "# ------------------------------\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "id": "i7Hcu6EZX2HW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# DCGAN Models\n",
        "# ------------------------------\n",
        "\n",
        "class DCGANGenerator(nn.Module):\n",
        "    def __init__(self, nz=128, ngf=64, nc=3):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input Z: (N, nz, 1, 1)\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf, nc, 3, 1, 1, bias=False),\n",
        "            nn.Tanh(),  # output in [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.main(z)\n",
        "\n",
        "\n",
        "class DCGANDiscriminator(nn.Module):\n",
        "    def __init__(self, ndf=64, nc=3):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input (N, 3, 32, 32)\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x).squeeze(1)  # (N,)\n"
      ],
      "metadata": {
        "id": "eDltxTWKX8ul"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# InceptionV3 Feature Extractor & FID\n",
        "# ------------------------------\n",
        "\n",
        "class InceptionV3Pool(nn.Module):\n",
        "    \"\"\"Pretrained InceptionV3 that outputs 2048-d pool features.\n",
        "    We apply the official weights' preprocess transforms.\n",
        "    \"\"\"\n",
        "    def __init__(self, device: torch.device):\n",
        "        super().__init__()\n",
        "        weights = Inception_V3_Weights.IMAGENET1K_V1\n",
        "        self.transforms = weights.transforms()  # handles resize(299), normalize\n",
        "        model = models.inception_v3(weights=weights, aux_logits=False)\n",
        "        model.fc = nn.Identity()  # output 2048-d embeddings\n",
        "        self.model = model.to(device).eval()\n",
        "        for p in self.model.parameters():\n",
        "            p.requires_grad_(False)\n",
        "        self.device = device\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def features(self, imgs: torch.Tensor, batch_size: int = 64) -> torch.Tensor:\n",
        "        \"\"\"imgs: float tensor in [0,1], shape (N,3,H,W). Returns (N,2048).\"\"\"\n",
        "        feats = []\n",
        "        self.model.eval()\n",
        "        n = imgs.size(0)\n",
        "        for i in range(0, n, batch_size):\n",
        "            batch = imgs[i:i+batch_size].cpu()\n",
        "            # apply transforms one-by-one (they expect PIL or tensors in [0,1])\n",
        "            # We'll map using a compiled transform to batch by for-loop to keep it simple\n",
        "            proc = torch.stack([self.transforms(x) for x in batch])  # (B,3,299,299)\n",
        "            proc = proc.to(self.device)\n",
        "            f = self.model(proc)  # (B,2048)\n",
        "            feats.append(f.detach().cpu())\n",
        "        return torch.cat(feats, dim=0)\n",
        "\n",
        "\n",
        "def cov_mean(feats: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"Compute mean and covariance (unbiased, N-1) for features (N,D).\"\"\"\n",
        "    x = feats.double()\n",
        "    mu = x.mean(dim=0)\n",
        "    xc = x - mu\n",
        "    # (D,D) covariance with unbiased denominator (N-1)\n",
        "    n = x.shape[0]\n",
        "    cov = (xc.t() @ xc) / (n - 1)\n",
        "    return mu.float(), cov.float()\n",
        "\n",
        "\n",
        "def _matrix_sqrt_psd(A: torch.Tensor, eps=1e-10) -> torch.Tensor:\n",
        "    \"\"\"Matrix square-root for symmetric PSD matrix using eigen-decomposition.\"\"\"\n",
        "    # ensure symmetry\n",
        "    A = (A + A.t()) * 0.5\n",
        "    evals, evecs = torch.linalg.eigh(A.double())\n",
        "    evals = torch.clamp(evals, min=0.0)\n",
        "    sqrt_evals = torch.sqrt(evals + eps)\n",
        "    sqrtA = (evecs * sqrt_evals.unsqueeze(0)) @ evecs.t()\n",
        "    return sqrtA.float()\n",
        "\n",
        "\n",
        "def frechet_distance(mu1: torch.Tensor, C1: torch.Tensor,\n",
        "                     mu2: torch.Tensor, C2: torch.Tensor, eps=1e-6) -> float:\n",
        "    \"\"\"Compute FID = ||mu1 - mu2||^2 + Tr(C1 + C2 - 2*sqrt(C1^{1/2} C2 C1^{1/2})).\"\"\"\n",
        "    mu1 = mu1.float(); mu2 = mu2.float()\n",
        "    C1 = C1.float(); C2 = C2.float()\n",
        "\n",
        "    diff = mu1 - mu2\n",
        "    # Compute sqrt( C1^{1/2} C2 C1^{1/2} ) via symmetric PSD trick\n",
        "    C1_sqrt = _matrix_sqrt_psd(C1 + eps * torch.eye(C1.shape[0]))\n",
        "    inner = C1_sqrt @ C2 @ C1_sqrt\n",
        "    inner = (inner + inner.t()) * 0.5  # symmetrize\n",
        "    covmean_sqrt = _matrix_sqrt_psd(inner + eps * torch.eye(inner.shape[0]))\n",
        "\n",
        "    tr = torch.trace(C1 + C2 - 2.0 * covmean_sqrt)\n",
        "    fid = diff.dot(diff) + tr\n",
        "    return float(fid.item())\n"
      ],
      "metadata": {
        "id": "vY2L5tyWYDJK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# Dataset & Utilities\n",
        "# ------------------------------\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    data_root: str = \"./data\"\n",
        "    outdir: str = \"./outputs\"\n",
        "    batch_size: int = 128\n",
        "    workers: int = 2\n",
        "    epochs: int = 10\n",
        "    lr: float = 2e-4\n",
        "    beta1: float = 0.5\n",
        "    nz: int = 128\n",
        "    ngf: int = 64\n",
        "    ndf: int = 64\n",
        "    fid_every: int = 1\n",
        "    num_fid_samples: int = 5000\n",
        "    seed: int = 42\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "def get_cifar10_loaders(cfg: TrainConfig):\n",
        "    # GAN training transform: [-1,1]\n",
        "    tf_train = transforms.Compose([\n",
        "        transforms.Resize(32),\n",
        "        transforms.CenterCrop(32),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "    train_set = datasets.CIFAR10(root=cfg.data_root, train=True, download=True, transform=tf_train)\n",
        "    train_loader = DataLoader(train_set, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.workers, drop_last=True)\n",
        "\n",
        "    # FID real features transform expects [0,1] images (we'll apply Inception transforms later)\n",
        "    tf_real = transforms.Compose([\n",
        "        transforms.Resize(32),\n",
        "        transforms.CenterCrop(32),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    real_eval_set = datasets.CIFAR10(root=cfg.data_root, train=True, download=True, transform=tf_real)\n",
        "    return train_loader, real_eval_set\n",
        "\n",
        "\n",
        "def denorm_to_01(x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Convert from [-1,1] to [0,1] range.\"\"\"\n",
        "    return x.add(1).div(2).clamp(0, 1)\n",
        "\n",
        "\n",
        "def save_image_grid(tensor: torch.Tensor, path: str, nrow: int = 8):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    grid = vutils.make_grid(tensor, nrow=nrow, padding=2)\n",
        "    vutils.save_image(grid, path)\n",
        "\n",
        "\n",
        "def plot_curves(curves: dict, path: str, title: str, ylabel: str):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    for k, v in curves.items():\n",
        "        xs = list(range(1, len(v)+1))\n",
        "        plt.plot(xs, v, label=k)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "5U5zQqFIYJAN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# FID computer (caches real stats)\n",
        "# ------------------------------\n",
        "\n",
        "class FIDEvaluator:\n",
        "    def __init__(self, device: torch.device, outdir: str, real_stats_path: str = None):\n",
        "        self.device = device\n",
        "        self.extractor = InceptionV3Pool(device)\n",
        "        self.outdir = outdir\n",
        "        os.makedirs(self.outdir, exist_ok=True)\n",
        "        self.real_stats_path = real_stats_path or os.path.join(self.outdir, \"cifar10_train_inception_stats.npz\")\n",
        "\n",
        "    def compute_real_stats(self, real_dataset: datasets.VisionDataset, max_items: int = None, batch: int = 128) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        if os.path.exists(self.real_stats_path):\n",
        "            arr = np.load(self.real_stats_path)\n",
        "            mu = torch.from_numpy(arr[\"mu\"]).float()\n",
        "            cov = torch.from_numpy(arr[\"cov\"]).float()\n",
        "            return mu, cov\n",
        "        loader = DataLoader(real_dataset, batch_size=batch, shuffle=False, num_workers=2)\n",
        "        feats = []\n",
        "        total = 0\n",
        "        for img, _ in loader:\n",
        "            if max_items is not None and total >= max_items:\n",
        "                break\n",
        "            img = img.to(self.device)\n",
        "            img01 = img  # already [0,1]\n",
        "            f = self.extractor.features(img01)\n",
        "            feats.append(f)\n",
        "            total += img.size(0)\n",
        "        feats = torch.cat(feats, dim=0)\n",
        "        mu, cov = cov_mean(feats)\n",
        "        np.savez(self.real_stats_path, mu=mu.numpy(), cov=cov.numpy())\n",
        "        return mu, cov\n",
        "\n",
        "    def compute_fake_stats(self, generator: nn.Module, nz: int, num_samples: int = 5000, batch: int = 128) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        feats = []\n",
        "        with torch.no_grad():\n",
        "            for _ in range(math.ceil(num_samples / batch)):\n",
        "                bs = min(batch, num_samples - len(feats)*batch)\n",
        "                z = torch.randn(bs, nz, 1, 1, device=self.device)\n",
        "                fake = generator(z)  # [-1,1]\n",
        "                fake01 = denorm_to_01(fake)\n",
        "                f = self.extractor.features(fake01)\n",
        "                feats.append(f)\n",
        "        feats = torch.cat(feats, dim=0)[:num_samples]\n",
        "        mu, cov = cov_mean(feats)\n",
        "        return mu, cov\n",
        "\n",
        "    def fid(self, mu_r: torch.Tensor, cov_r: torch.Tensor, mu_f: torch.Tensor, cov_f: torch.Tensor) -> float:\n",
        "        return frechet_distance(mu_r, cov_r, mu_f, cov_f)\n",
        "\n",
        "    def tsne_plot(self, real_dataset: datasets.VisionDataset, generator: nn.Module, nz: int, path: str, num_per_class: int = 300):\n",
        "        if not _HAVE_SK:\n",
        "            return  # skip if sklearn not present\n",
        "        # sample subset from real\n",
        "        loader = DataLoader(real_dataset, batch_size=256, shuffle=True, num_workers=2)\n",
        "        imgs_real = []\n",
        "        for img, _ in loader:\n",
        "            imgs_real.append(img)\n",
        "            if sum(x.size(0) for x in imgs_real) >= num_per_class:\n",
        "                break\n",
        "        Xr = torch.cat(imgs_real, dim=0)[:num_per_class].to(self.device)\n",
        "        Xr_f = self.extractor.features(Xr)\n",
        "        # sample fake\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(num_per_class, nz, 1, 1, device=self.device)\n",
        "            Xf = generator(z)\n",
        "            Xf01 = denorm_to_01(Xf)\n",
        "            Xf_f = self.extractor.features(Xf01)\n",
        "        X = torch.cat([Xr_f, Xf_f], dim=0).cpu().numpy()\n",
        "        y = np.array([0]*num_per_class + [1]*num_per_class)\n",
        "        tsne = TSNE(n_components=2, init=\"random\", random_state=42, perplexity=30)\n",
        "        emb = tsne.fit_transform(X)\n",
        "        # plot\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        plt.figure(figsize=(6,6))\n",
        "        plt.scatter(emb[y==0,0], emb[y==0,1], alpha=0.6, label=\"Real\")\n",
        "        plt.scatter(emb[y==1,0], emb[y==1,1], alpha=0.6, label=\"Fake\")\n",
        "        plt.legend(); plt.title(\"t-SNE of Inception Features (Real vs Fake)\")\n",
        "        plt.tight_layout(); plt.savefig(path); plt.close()\n"
      ],
      "metadata": {
        "id": "rSMM7EX5YOvS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# Trainer\n",
        "# ------------------------------\n",
        "\n",
        "class GANTrainer:\n",
        "    def __init__(self, cfg: TrainConfig):\n",
        "        self.cfg = cfg\n",
        "        self.device = torch.device(cfg.device)\n",
        "        set_seed(cfg.seed)\n",
        "        os.makedirs(cfg.outdir, exist_ok=True)\n",
        "\n",
        "        # Data\n",
        "        self.train_loader, self.real_eval_set = get_cifar10_loaders(cfg)\n",
        "\n",
        "        # Models\n",
        "        self.netG = DCGANGenerator(cfg.nz, cfg.ngf).to(self.device)\n",
        "        self.netD = DCGANDiscriminator(cfg.ndf).to(self.device)\n",
        "        self._init_weights()\n",
        "\n",
        "        # Loss/Opt\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "        self.optG = optim.Adam(self.netG.parameters(), lr=cfg.lr, betas=(cfg.beta1, 0.999))\n",
        "        self.optD = optim.Adam(self.netD.parameters(), lr=cfg.lr, betas=(cfg.beta1, 0.999))\n",
        "\n",
        "        # Fixed noise for grids\n",
        "        self.fixed_z = torch.randn(64, cfg.nz, 1, 1, device=self.device)\n",
        "\n",
        "        # FID evaluator & cached real stats\n",
        "        self.fid_eval = FIDEvaluator(self.device, cfg.outdir)\n",
        "        self.mu_r, self.cov_r = self.fid_eval.compute_real_stats(self.real_eval_set)\n",
        "\n",
        "        # Logs\n",
        "        self.hist_G: List[float] = []\n",
        "        self.hist_D: List[float] = []\n",
        "        self.hist_FID: List[float] = []\n",
        "\n",
        "    def _init_weights(self):\n",
        "        def weights_init(m):\n",
        "            classname = m.__class__.__name__\n",
        "            if classname.find('Conv') != -1:\n",
        "                nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "            elif classname.find('BatchNorm') != -1:\n",
        "                nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "                nn.init.constant_(m.bias.data, 0)\n",
        "        self.netG.apply(weights_init)\n",
        "        self.netD.apply(weights_init)\n",
        "\n",
        "    def train_epoch(self, epoch: int):\n",
        "        self.netG.train(); self.netD.train()\n",
        "        running_G, running_D = 0.0, 0.0\n",
        "        for i, (imgs, _) in enumerate(self.train_loader):\n",
        "            b = imgs.size(0)\n",
        "            real = imgs.to(self.device)  # [-1,1]\n",
        "            z = torch.randn(b, self.cfg.nz, 1, 1, device=self.device)\n",
        "            fake = self.netG(z)\n",
        "\n",
        "            # Train D: maximize log D(real) + log(1 - D(fake))\n",
        "            self.optD.zero_grad()\n",
        "            pred_real = self.netD(real)\n",
        "            pred_fake = self.netD(fake.detach())\n",
        "            loss_D = self.criterion(pred_real, torch.ones_like(pred_real)) + \\\n",
        "                     self.criterion(pred_fake, torch.zeros_like(pred_fake))\n",
        "            loss_D.backward()\n",
        "            self.optD.step()\n",
        "\n",
        "            # Train G: maximize log D(fake)\n",
        "            self.optG.zero_grad()\n",
        "            pred_fake2 = self.netD(fake)\n",
        "            loss_G = self.criterion(pred_fake2, torch.ones_like(pred_fake2))\n",
        "            loss_G.backward()\n",
        "            self.optG.step()\n",
        "\n",
        "            running_G += loss_G.item()\n",
        "            running_D += loss_D.item()\n",
        "\n",
        "            if (i+1) % 100 == 0:\n",
        "                print(f\"Epoch {epoch:03d} [{i+1:04d}/{len(self.train_loader)}]  D: {loss_D.item():.3f}  G: {loss_G.item():.3f}\")\n",
        "\n",
        "        mean_G = running_G / len(self.train_loader)\n",
        "        mean_D = running_D / len(self.train_loader)\n",
        "        self.hist_G.append(mean_G)\n",
        "        self.hist_D.append(mean_D)\n",
        "\n",
        "        # Save sample grid for the epoch\n",
        "        with torch.no_grad():\n",
        "            sample = self.netG(self.fixed_z)\n",
        "            sample01 = denorm_to_01(sample)\n",
        "            save_image_grid(sample01, os.path.join(self.cfg.outdir, f\"samples/epoch_{epoch:03d}.png\"), nrow=8)\n",
        "\n",
        "    def evaluate_fid(self, epoch: int):\n",
        "        mu_f, cov_f = self.fid_eval.compute_fake_stats(self.netG, self.cfg.nz, self.cfg.num_fid_samples)\n",
        "        fid = self.fid_eval.fid(self.mu_r, self.cov_r, mu_f, cov_f)\n",
        "        self.hist_FID.append(fid)\n",
        "        print(f\"[FID] Epoch {epoch:03d}  FID = {fid:.2f}\")\n",
        "\n",
        "    def post_plots(self):\n",
        "        # Loss curves\n",
        "        plot_curves({\"G\": self.hist_G, \"D\": self.hist_D}, os.path.join(self.cfg.outdir, \"curves/loss_curves.png\"),\n",
        "                    title=\"GAN Loss Curves\", ylabel=\"Loss\")\n",
        "        # FID curve\n",
        "        if len(self.hist_FID) > 0:\n",
        "            plot_curves({\"FID\": self.hist_FID}, os.path.join(self.cfg.outdir, \"curves/fid_curve.png\"),\n",
        "                        title=\"FID over Epochs\", ylabel=\"FID (lower is better)\")\n",
        "\n",
        "        # t-SNE of features at the end (optional if sklearn available)\n",
        "        try:\n",
        "            self.fid_eval.tsne_plot(self.real_eval_set, self.netG, self.cfg.nz,\n",
        "                                    os.path.join(self.cfg.outdir, \"curves/tsne_features.png\"))\n",
        "        except Exception as e:\n",
        "            print(f\"t-SNE plot skipped: {e}\")\n",
        "\n",
        "    def run(self):\n",
        "        for epoch in range(1, self.cfg.epochs + 1):\n",
        "            self.train_epoch(epoch)\n",
        "            if (epoch % self.cfg.fid_every) == 0:\n",
        "                self.evaluate_fid(epoch)\n",
        "        self.post_plots()\n",
        "        print(\"Training complete. Outputs saved to:\", self.cfg.outdir)\n"
      ],
      "metadata": {
        "id": "aIXRacUwYVoh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jhLgeoV0XWGH"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Main\n",
        "# ------------------------------\n",
        "\n",
        "def parse_args() -> TrainConfig:\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument('--data_root', type=str, default='./data')\n",
        "    p.add_argument('--outdir', type=str, default='./outputs')\n",
        "    p.add_argument('--batch_size', type=int, default=128)\n",
        "    p.add_argument('--workers', type=int, default=2)\n",
        "    p.add_argument('--epochs', type=int, default=10)\n",
        "    p.add_argument('--lr', type=float, default=2e-4)\n",
        "    p.add_argument('--beta1', type=float, default=0.5)\n",
        "    p.add_argument('--nz', type=int, default=128)\n",
        "    p.add_argument('--ngf', type=int, default=64)\n",
        "    p.add_argument('--ndf', type=int, default=64)\n",
        "    p.add_argument('--fid_every', type=int, default=1)\n",
        "    p.add_argument('--num_fid_samples', type=int, default=5000)\n",
        "    p.add_argument('--seed', type=int, default=42)\n",
        "    p.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    args = p.parse_args(args=None if __name__ == '__main__' else [])\n",
        "    return TrainConfig(**vars(args))\n",
        "\n",
        "\n",
        "def main():\n",
        "    cfg = parse_args()\n",
        "\n",
        "    print(\"\\nFréchet Frontier — DCGAN + FID Evaluation Suite (PyTorch)\")\n",
        "    print(\"Config:\", cfg)\n",
        "\n",
        "    trainer = GANTrainer(cfg)\n",
        "    trainer.run()\n"
      ]
    }
  ]
}